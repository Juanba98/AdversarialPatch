{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hP6YqNeAXL9_ydtyb9tteFg8Uchp-3iU",
      "authorship_tag": "ABX9TyPdtRsmJAf7YN7jqQnlYxGL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "85754d59bd504c67894a5b9bec6cfbfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_264d1427cd3a4498ba2c9cad7fb22665",
              "IPY_MODEL_eabec7a94c8240a6b31db93294d4e252",
              "IPY_MODEL_46adabc52f2f4f6c9b828e537464f509"
            ],
            "layout": "IPY_MODEL_00831ba99b794402a8a129be71fb1cf9"
          }
        },
        "264d1427cd3a4498ba2c9cad7fb22665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23eb216b4f8f4a8eb6ff1c6572d6880f",
            "placeholder": "​",
            "style": "IPY_MODEL_94c7e96dec7d494bb3cda79bad311714",
            "value": "100%"
          }
        },
        "eabec7a94c8240a6b31db93294d4e252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a928a3672e404cc5b75f87faf60aab33",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ce52edf4e534e3eb7756b7abefc856d",
            "value": 170498071
          }
        },
        "46adabc52f2f4f6c9b828e537464f509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_950040ec2a53447c8b5b66a45aedb002",
            "placeholder": "​",
            "style": "IPY_MODEL_8d154456be044d0ea5a94daed27dcdf1",
            "value": " 170498071/170498071 [00:05&lt;00:00, 33592258.06it/s]"
          }
        },
        "00831ba99b794402a8a129be71fb1cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23eb216b4f8f4a8eb6ff1c6572d6880f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94c7e96dec7d494bb3cda79bad311714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a928a3672e404cc5b75f87faf60aab33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce52edf4e534e3eb7756b7abefc856d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "950040ec2a53447c8b5b66a45aedb002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d154456be044d0ea5a94daed27dcdf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Juanba98/AdversarialPatch/blob/main/Carlini%26Wagner_L2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORyaBeRSvbnk",
        "outputId": "caa7f7fb-c834-4d47-c6c1-044bf05739cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision  --extra-index-url https://download.pytorch.org/whl/cu116"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Carlini-Wagner attack (http://arxiv.org/abs/1608.04644).\n",
        "Referential implementation:\n",
        "- https://github.com/carlini/nn_robust_attacks.git (the original implementation)\n",
        "- https://github.com/kkew3/pytorch-cw2/blob/master/cw.py\n",
        "\"\"\"\n",
        "\n",
        "import operator as op\n",
        "\n",
        "from typing import Union, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "W1b0se8Oys1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# L2 attack\n",
        "To ensure the modifitacions yields to a valid image, we use the third method of box contraints at the paper and we define  $\\delta$ as:\n",
        "\n",
        "$$\\delta_{i} = \\frac{1}{2}(tanh(w_{i}) + 1) - x_{i} $$\n",
        "\n",
        "and we optimize over the variable $w$\n",
        "\n",
        "\\\n",
        "\n",
        "## Attack\n",
        "\n",
        "Given x, and choosing a target class $t$  ($t \\neq C^{*}(x)$, beeing $C^{*}(x)$) the correct label of x we search for a $w$ that solves\n",
        "\n",
        "\n",
        "\n",
        "$$minimize \\ ||\\delta||^{2}_{2} + c \\cdot f(x + \\delta)$$ \n",
        "\n",
        "\n",
        "\n",
        "with $f$ defined as\n",
        "\n",
        "$$f(x') = max(max\\{Z(x')_i :  i \\neq t\\} - Z(x')_t, -\\kappa)$$\n",
        "\n",
        "To control the confidence with which missclasifation ocurrs we adjust κ but we wil set it to 0 for out attack\n",
        "\n",
        " \n",
        "## L2 formula\n"
      ],
      "metadata": {
        "id": "9jDZY4NAHwfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hiperparametros"
      ],
      "metadata": {
        "id": "UwR6jWQ5AY6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEARCH_STEPS = 9  # number of times to adjust the constant with binary search\n",
        "MAX_ITERATIONS = 10000   # number of iterations to perform gradient descent\n",
        "ABORT_EARLY = True       # if we stop improving, abort gradient descent early\n",
        "LEARNING_RATE = 1e-2     # larger values converge faster to less accurate results\n",
        "TARGETED = True          # should we target one specific class? or just be wrong?\n",
        "K = 0             # (kappa) how strong the adversarial example should be (confidence)\n",
        "INITIAL_CONST = 1e-3     # the initial constant c to pick as a first guess"
      ],
      "metadata": {
        "id": "_WaGTOKoAYZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "cXVs7HAbCwkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class L2Adversary(object):\n",
        "  \n",
        " \n",
        "  def __init__(self, targeted=True, k=K, c_range=(INITIAL_CONST, 1e10),\n",
        "                  search_steps=SEARCH_STEPS, max_steps=1000, abort_early=ABORT_EARLY,\n",
        "                  box=(-1., 1.), learning_rate = LEARNING_RATE):\n",
        "\n",
        "\n",
        "  \n",
        "    self.targeted = targeted # type: bool param: True for targeted attack\n",
        "    self.k = float(k) #type: int param: confidence\n",
        "    self.c_range = (float(c_range[0]), float(c_range[1])) # type: Tuple[float, float], param: range of the constat c\n",
        "    self.binary_search_steps = search_steps #type: int param: number of steps to perform binary search to find optimal c\n",
        "    self.max_steps = max_steps #type: int param: Maximum number of iterations\n",
        "    self.abort_early = abort_early #type bool param: If true, we break when the gradient descent gets stuck\n",
        "    self.box = tuple(map(float, box))  # type: Tuple[float, float], param: (max,min) pixel value\n",
        "    self.learning_rate = learning_rate #type: float param: the learning rate for Adam optimizer used over the perturbation\n",
        "    self.ae_tol = 1e-4  # tolerance of early abort\n",
        "    \n",
        "    #?\n",
        "    self.repeat = (self.binary_search_steps >= 10)\n",
        "\n",
        "    #Used for the affine transformation fo the change-of-variable\n",
        "    self.box_mul = (self.box[1]-self.box[0])/2\n",
        "    self.box_plus = (self.box[1]+self.box[0])/2\n",
        "\n",
        "  def attack(self,model, inputs, targets, num_classes ):\n",
        "\n",
        "\n",
        "    '''\n",
        "    :param model: Model to attack :type: nn.Module  \n",
        "    :param inputs: original images of dimension [B x C x H x W].\n",
        "    :param targets: the original image labels, or the attack target, of\n",
        "              dimension [B]. If ``self.targeted`` is ``True``, then ``targets``\n",
        "              is treated as the attack targets, otherwise the labels.\n",
        "              :type: ???????????????????????\n",
        "    :param num_clases: number of clases of the model :type: int  \n",
        "    :return: Adversarial examples of dimension [B X C x H x W]\n",
        "    '''\n",
        "\n",
        "\n",
        "    # sanity check\n",
        "    assert isinstance(model, nn.Module)\n",
        "    assert len(inputs.size()) == 4\n",
        "    assert len(targets.size()) == 1\n",
        "\n",
        "\n",
        "    # get a copy of targets in numpy before moving to GPU, used when doing\n",
        "    # the binary search on `scale_const`\n",
        "    targets_np = targets.clone().cpu().numpy().astype(int)  # type: np.ndarray\n",
        "\n",
        "    # we move the tensor to the same device as the model \n",
        "    inputs = inputs.to(device)  # type: torch.FloatTensor\n",
        "    targets = targets.to(device)  # type: torch.FloatTensor \n",
        "\n",
        "\n",
        "    batch_size = targets.size()[0]  # type: int\n",
        " \n",
        "    # `lower_bounds_np`, `upper_bounds_np` and `scale_consts_np` are used\n",
        "    # for binary search of each `scale_const` in the batch. The element-wise\n",
        "    # inquality holds: lower_bounds_np < scale_consts_np <= upper_bounds_np\n",
        "    lower_bounds_np = np.zeros(batch_size)\n",
        "    upper_bounds_np = np.ones(batch_size) * self.c_range[1]\n",
        "    scale_consts_np = np.ones(batch_size) * self.c_range[0]\n",
        "\n",
        "   \n",
        "\n",
        "    # Optimal attack to be found.\n",
        "    # The three \"placeholders\" are defined as:\n",
        "    # - `o_best_l2`: the least L2 norms\n",
        "    # - `o_best_l2_ppred`: the perturbed predictions made by the adversarial\n",
        "    #    perturbations with the least L2 norms\n",
        "    # - `o_best_advx`: the underlying adversarial example of\n",
        "    #   `o_best_l2_ppred`\n",
        "    o_best_l2 = np.ones(batch_size) * np.inf #size [B]\n",
        "    o_best_l2_ppred = -np.ones(batch_size) #size [B]\n",
        "    o_best_advx = inputs.clone().cpu().numpy()  # type: np.ndarray size [B x C x H x W]\n",
        "    print(f' best_advx size: {o_best_advx.size}')\n",
        "\n",
        "    # convert `inputs` to tanh-space\n",
        "    inputs_tanh = self.atanh((inputs - self.box_plus) / self.box_mul)  # type: torch.FloatTensor\n",
        "    #print(f'inputs_tanh: {inputs_tanh}')\n",
        "    inputs_tanh_aux = torch.atanh((inputs - self.box_plus) / self.box_mul)\n",
        "    #print(f'inputs_tanh_aux: {inputs_tanh_aux}')\n",
        "\n",
        "    \n",
        "\n",
        "    # the one-hot encoding of `targets`\n",
        "    targets_oh = torch.zeros(targets.size() + (num_classes,) ,requires_grad = False)  # type: torch.FloatTensor\n",
        "    #print(f'targets_oh size: {targets_oh.size()}')\n",
        "\n",
        "    #targets.unsqueeze(1) type:torch.FloatTensor but scatter need a LongTensor as a index \n",
        "    targets_oh.scatter_(1, targets.unsqueeze(1).type('torch.LongTensor'), 1.0)\n",
        "\n",
        "    targets_oh = targets_oh.to(device)\n",
        "    #print(f'targets_oh: {targets_oh}')\n",
        "\n",
        "   \n",
        "    #the perturbation in tanh-space\n",
        "    pert_tanh = nn.Parameter(torch.zeros_like(inputs))  # type: torch.FloatTensor\n",
        "\n",
        "    \n",
        "    optimizer = optim.Adam([pert_tanh], lr=self.learning_rate)\n",
        "    \n",
        "\n",
        "    for outer_step  in range(self.binary_search_steps):\n",
        "\n",
        "      #?\n",
        "      if self.repeat and outer_step == self.binary_search_steps - 1:\n",
        "        scale_consts_np = upper_bounds_np\n",
        "\n",
        "      \n",
        "      #We convert the np.array to a tensor\n",
        "      scale_consts = torch.tensor(np.copy(scale_consts_np)).float()  # type: torch.FloatTensor\n",
        "      scale_consts = scale_consts.to(device)\n",
        "      #print('Using scale consts:', list(scale_consts_np))  # FIXME\n",
        "\n",
        "      #print(scale_consts.size())\n",
        "      # the minimum L2 norms of perturbations found during optimization\n",
        "      best_l2 = np.ones(batch_size) * np.inf\n",
        "\n",
        "      # the perturbed predictions corresponding to `best_l2`, to be used\n",
        "      # in binary search of `scale_const`\n",
        "      best_l2_ppred = -np.ones(batch_size)\n",
        "\n",
        "      # previous (summed) batch loss, to be used in early stopping policy\n",
        "      prev_batch_loss = np.inf  # type: float\n",
        "\n",
        "      for optim_step in range(self.max_steps):\n",
        "\n",
        "        batch_loss, pert_norms_np, pert_outputs_np, advxs_np = \\\n",
        "            self._optimize(model, optimizer, inputs_tanh,\n",
        "                            pert_tanh,  targets_oh,\n",
        "                            scale_consts)\n",
        "            \n",
        "        if optim_step % 10 == 0: print(f'batch {optim_step} loss: {batch_loss}')  # FIXME\n",
        "\n",
        "        if self.abort_early and not optim_step % (self.max_steps // 10):\n",
        "\n",
        "            #If loss increse enough we abort\n",
        "            if batch_loss > prev_batch_loss * (1 - self.ae_tol):\n",
        "                break\n",
        "            prev_batch_loss = batch_loss\n",
        "\n",
        "        # update best attack found during optimization\n",
        "        pert_predictions_np = np.argmax(pert_outputs_np, axis=1)\n",
        "\n",
        "        print(f'pert_predictions_np: {pert_predictions_np} ')\n",
        "\n",
        "        comp_pert_predictions_np = np.argmax(\n",
        "                self._compensate_confidence(pert_outputs_np,\n",
        "                                            targets_np),\n",
        "                axis=1)\n",
        "       \n",
        "        #for each image\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            l2 = pert_norms_np[i]\n",
        "            cppred = comp_pert_predictions_np[i]\n",
        "            ppred = pert_predictions_np[i]\n",
        "            tlabel = targets_np[i]\n",
        "            ax = advxs_np[i]\n",
        "            if self._attack_successful(cppred, tlabel):\n",
        "                assert cppred == ppred\n",
        "                if l2 < best_l2[i]:\n",
        "                    best_l2[i] = l2\n",
        "                    best_l2_ppred[i] = ppred\n",
        "                if l2 < o_best_l2[i]:\n",
        "                    o_best_l2[i] = l2\n",
        "                    o_best_l2_ppred[i] = ppred\n",
        "                    o_best_advx[i] = ax\n",
        "\n",
        "\n",
        "      # binary search of `scale_const`\n",
        "      for i in range(batch_size):\n",
        "          tlabel = targets_np[i]\n",
        "          assert best_l2_ppred[i] == -1 or \\\n",
        "                  self._attack_successful(best_l2_ppred[i], tlabel)\n",
        "          assert o_best_l2_ppred[i] == -1 or \\\n",
        "                  self._attack_successful(o_best_l2_ppred[i], tlabel)\n",
        "          if best_l2_ppred[i] != -1:\n",
        "              # successful; attempt to lower `scale_const` by halving it\n",
        "              if scale_consts_np[i] < upper_bounds_np[i]:\n",
        "                  upper_bounds_np[i] = scale_consts_np[i]\n",
        "              # `upper_bounds_np[i] == c_range[1]` implies no solution found\n",
        "             \n",
        "              if upper_bounds_np[i] < self.c_range[1] * 0.1:\n",
        "                  scale_consts_np[i] = (lower_bounds_np[i] + upper_bounds_np[i]) / 2\n",
        "          else:\n",
        "              # failure; multiply `scale_const` by ten if no solution\n",
        "              # found; otherwise do binary search\n",
        "              if scale_consts_np[i] > lower_bounds_np[i]:\n",
        "                  lower_bounds_np[i] = scale_consts_np[i]\n",
        "              if upper_bounds_np[i] < self.c_range[1] * 0.1:\n",
        "                  scale_consts_np[i] = (lower_bounds_np[i] + upper_bounds_np[i]) / 2\n",
        "              else:\n",
        "                  scale_consts_np[i] *= 10\n",
        "\n",
        "    #if not to_numpy:\n",
        "    o_best_advx = torch.from_numpy(o_best_advx).float()\n",
        "    return o_best_advx\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def _optimize(self, model, optimizer, inputs_tanh_var, pert_tanh_var,\n",
        "                  targets_oh_var, c_var):\n",
        "        \"\"\"\n",
        "        Optimize for one step.\n",
        "        :param model: the model to attack\n",
        "        :type model: nn.Module\n",
        "        :param optimizer: the Adam optimizer to optimize pert_tanh\n",
        "        :type optimizer: optim.Adam\n",
        "        :param inputs_tanh_var: the input images in tanh-space\n",
        "        :type inputs_tanh_var: torch.FloatTensor\n",
        "        :param pert_tanh_var: the perturbation to optimize in tanh-space\n",
        "        :type pert_tanh_var: torch.FloatTensor\n",
        "        :param targets_oh_var: the one-hot encoded target tensor (the attack\n",
        "               targets if self.targeted else image labels)\n",
        "        :type targets_oh_var: torch.FloatTensor\n",
        "        :param c_var: the constant `c` for each perturbation of a batch,\n",
        "               a Variable of FloatTensor of dimension [B]\n",
        "        :type c_var: torch.FloatTensor\n",
        "        :return: the batch loss, squared L2-norm of adversarial perturbations\n",
        "                 (of dimension [B]), the perturbed activations (of dimension\n",
        "                 [B]), the adversarial examples (of dimension [B x C x H x W])\n",
        "        \"\"\"\n",
        "        # the adversarial examples in the image space\n",
        "        # of dimension [B x C x H x W]\n",
        "\n",
        "        #print(f'pert_tanh_var before:  {pert_tanh_var}')\n",
        "        advxs_var = torch.tanh(inputs_tanh_var + pert_tanh_var) * self.box_mul + self.box_plus \n",
        "        advxs_var.to(device)\n",
        "       \n",
        "\n",
        "        # Do optimization for one step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #eval?\n",
        "        # the perturbed activation before softmax\n",
        "        pert_outputs_var = model(advxs_var)  # type: ?\n",
        "        \n",
        "\n",
        "        # the original inputs\n",
        "        inputs_var = torch.tanh(inputs_tanh_var) * self.box_mul + self.box_plus  # type: ?\n",
        "\n",
        "        #https://pytorch.org/docs/stable/generated/torch.linalg.norm.html#torch.linalg.norm\n",
        "        perts_norm_var = torch.pow(advxs_var - inputs_var, 2)\n",
        "        perts_norm_var = torch.sum(perts_norm_var.view(\n",
        "                perts_norm_var.size(0), -1), 1)\n",
        "        \n",
        "        # In Carlini's code, `target_activ_var` is called `real`.\n",
        "        # It should be a  tensor of dimension [B], such that the\n",
        "        # `target_activ_var[i]` is the final activation (right before softmax)\n",
        "        # of the $t$th class, where $t$ is the attack target or the image label\n",
        "        #Z(t)\n",
        "        # noinspection PyArgumentList\n",
        "        \n",
        "        \n",
        "        target_activ_var = torch.sum(targets_oh_var * pert_outputs_var, 1)\n",
        "        inf = 1e4  \n",
        "       \n",
        "        # noinspection PyArgumentList\n",
        "        assert (pert_outputs_var.max(1)[0] >= -inf).all(), 'assumption failed'\n",
        "        # noinspection PyArgumentList\n",
        "\n",
        "        # compute the probability of the label class versus the maximum other\n",
        "        maxother_activ_var = torch.max(((1 - targets_oh_var) * pert_outputs_var\n",
        "                                        - targets_oh_var * inf), 1)[0]\n",
        "\n",
        "        # Compute $f(x')$, where $x'$ is the adversarial example in image space.\n",
        "        # The result `f_var` should be of dimension [B]\n",
        "        if self.targeted:\n",
        "            # if targeted, optimize to make `target_activ_var` larger than\n",
        "            # `maxother_activ_var` by `self.k`\n",
        "            #\n",
        "            # noinspection PyArgumentList\n",
        "            f_var = torch.clamp(maxother_activ_var - target_activ_var\n",
        "                                + self.k, min=0.0)\n",
        "        else:\n",
        "            # if not targeted, optimize to make `maxother_activ_var` larger than\n",
        "            # `target_activ_var` (the ground truth image labels) by\n",
        "            # `self.k`\n",
        "            #\n",
        "            # noinspection PyArgumentList\n",
        "            f_var = torch.clamp(target_activ_var - maxother_activ_var\n",
        "                                + self.k, min=0.0)\n",
        "        # the total loss of current batch, should be of dimension [1]\n",
        "        #print(f'perts_norm_var = {perts_norm_var}' )\n",
        "        #print(f'c_var = {c_var}' )\n",
        "        #print(f'f_var = {f_var}' )\n",
        "      \n",
        "        loss = torch.sum(perts_norm_var + c_var * f_var) # type: Variable\n",
        "\n",
        "     \n",
        "        #Back propagation\n",
        "        loss.backward()\n",
        "        #Updates the parameters\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        #print(f'pert_tanh_var after:  {pert_tanh_var}')\n",
        "        \n",
        "        # Make some records in python/numpy on CPU\n",
        "        batch_loss = loss.data  # type: float\n",
        "        pert_norms_np = perts_norm_var.data.cpu().numpy()\n",
        "        pert_outputs_np = pert_outputs_var.data.cpu().numpy()\n",
        "        advxs_np = advxs_var.data.cpu().numpy()\n",
        "        return batch_loss, pert_norms_np, pert_outputs_np, advxs_np\n",
        "\n",
        "  # noinspection PyUnresolvedReferences\n",
        "  def _compensate_confidence(self, outputs, targets):\n",
        "      \"\"\"\n",
        "      Compensate for ``self.k`` and returns a new weighted sum\n",
        "      vector.\n",
        "      :param outputs: the weighted sum right before the last layer softmax\n",
        "              normalization, of dimension [B x M]\n",
        "      :type outputs: np.ndarray\n",
        "      :param targets: either the attack targets or the real image labels,\n",
        "              depending on whether or not ``self.targeted``, of dimension [B]\n",
        "      :type targets: np.ndarray\n",
        "      :return: the compensated weighted sum of dimension [B x M]\n",
        "      :rtype: np.ndarray\n",
        "      \"\"\"\n",
        "      outputs_comp = np.copy(outputs)\n",
        "      rng = np.arange(targets.shape[0])\n",
        "\n",
        "      #print(rng.dtype)\n",
        "      #print(targets.dtype)\n",
        "      #print(outputs_comp.shape)\n",
        "      if self.targeted:\n",
        "          # for each image i:\n",
        "          # if targeted, outputs[i, target_onehot] (target) should be larger than\n",
        "          # max(outputs[i, ~target_onehot]) (max (~target)) by self.k\n",
        "          # The target label should be larger than\n",
        "          \n",
        "          outputs_comp[rng, targets] -= self.k\n",
        "      else:\n",
        "          # for each image $i$:\n",
        "          # if not targeted, `max(outputs[i, ~target_onehot]` should be larger\n",
        "          # than `outputs[i, target_onehot]` (the ground truth image labels)\n",
        "          # by `self.k`\n",
        "          outputs_comp[rng, targets] += self.k\n",
        "\n",
        "\n",
        "      return outputs_comp\n",
        "\n",
        "\n",
        "  def _attack_successful(self, prediction, target):\n",
        "    \"\"\"\n",
        "    See whether the underlying attack is successful.\n",
        "    :param prediction: the prediction of the model on an input\n",
        "    :type prediction: int\n",
        "    :param target: either the attack target or the ground-truth image label\n",
        "    :type target: int\n",
        "    :return: ``True`` if the attack is successful\n",
        "    :rtype: bool\n",
        "    \"\"\"\n",
        "   \n",
        "    if self.targeted:\n",
        "        return prediction == target\n",
        "    else:\n",
        "        return prediction != target\n",
        "\n",
        "\n",
        "  def atanh(self, x, eps=1e-6):\n",
        "    \"\"\"\n",
        "    :param x: a tensor \n",
        "    :param eps: used to enhance numeric stability\n",
        "    :return: :math:`\\\\tanh^{-1}{x}`, of the same type as ``x``\n",
        "    \"\"\"\n",
        "    x = x * (1 - eps)\n",
        "    return 0.5 * torch.log((1.0 + x) / (1.0 - x))\n"
      ],
      "metadata": {
        "id": "9TH9qzesy7Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "tjEQna0jk3xO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean = [0.5,0.5,0.5]\n",
        "std =  [0.5,0.5,0.5]\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(datasets.CIFAR10(root = '/content/CIFAR10', train=True, download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize(mean = mean, std = std),\n",
        "                           ])),  shuffle=True, batch_size = batch_size, num_workers = 2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "NUM_CLASSES = len(classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "85754d59bd504c67894a5b9bec6cfbfe",
            "264d1427cd3a4498ba2c9cad7fb22665",
            "eabec7a94c8240a6b31db93294d4e252",
            "46adabc52f2f4f6c9b828e537464f509",
            "00831ba99b794402a8a129be71fb1cf9",
            "23eb216b4f8f4a8eb6ff1c6572d6880f",
            "94c7e96dec7d494bb3cda79bad311714",
            "a928a3672e404cc5b75f87faf60aab33",
            "9ce52edf4e534e3eb7756b7abefc856d",
            "950040ec2a53447c8b5b66a45aedb002",
            "8d154456be044d0ea5a94daed27dcdf1"
          ]
        },
        "id": "kIC1YXdOk3RW",
        "outputId": "a0d29bda-7bb6-4449-ee45-49abfa55733b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/CIFAR10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85754d59bd504c67894a5b9bec6cfbfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/CIFAR10/cifar-10-python.tar.gz to /content/CIFAR10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CifarCNN"
      ],
      "metadata": {
        "id": "6A1JNkw0n-Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CifarCNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CifarCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.fc5 = nn.Linear(512, 256)\n",
        "        self.fc6 = nn.Linear(256, 256)\n",
        "        self.fc7 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.bn1(self.conv1(x)))\n",
        "        h = F.relu(self.bn2(self.conv2(h)))\n",
        "        h = F.max_pool2d(h, 4)\n",
        "\n",
        "        h = F.relu(self.bn3(self.conv3(h)))\n",
        "        h = F.relu(self.bn4(self.conv4(h)))\n",
        "        h = F.max_pool2d(h, 4)\n",
        "\n",
        "        h = F.relu(self.fc5(h.view(h.size(0), -1)))\n",
        "        h = F.relu(self.fc6(h))\n",
        "        h = self.fc7(h)\n",
        "        return F.log_softmax(h)\n",
        "\n",
        "model = CifarCNN()"
      ],
      "metadata": {
        "id": "4_YBtM_LoCBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA_YRyZHotVj",
        "outputId": "19ab3a6e-7c27-46b3-fc1b-ec1d7817e2f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/TFG/CIFAR10/CIFAR10cifar_net.pth'\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "inputs_box = (min((0 - m) / s for m, s in zip(mean, std)),\n",
        "              max((1 - m) / s for m, s in zip(mean, std)))\n",
        "\n",
        "# a targeted adversary\n",
        "adversary = L2Adversary(targeted=True,\n",
        "                           k=0.0,\n",
        "                           search_steps=10,\n",
        "                           box=inputs_box,\n",
        "                           learning_rate=5e-4)\n",
        "\n",
        "\n",
        "inputs, _ = next(iter(dataloader)) #inputs images\n",
        "inputs.to(device)\n",
        "target_class_idx = 3\n",
        "attack_targets = torch.ones(inputs.size(0)) * target_class_idx #target one-hot encoded\n",
        "\n",
        "\n",
        "adversarial_examples = adversary.attack(model, inputs, attack_targets, NUM_CLASSES)\n",
        "assert isinstance(adversarial_examples, torch.FloatTensor)\n",
        "assert adversarial_examples.size() == inputs.size()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH6v1SF6kR5c",
        "outputId": "149d67c2-c44d-4619-ea03-9c0ae1fdf14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " best_advx size: 12288\n",
            "batch 0 loss: 0.004153944086283445\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 10 loss: 0.004434225149452686\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 20 loss: 0.004206349607557058\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 30 loss: 0.004132003523409367\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 40 loss: 0.004127705469727516\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 50 loss: 0.004125688690692186\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 60 loss: 0.004124117083847523\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 70 loss: 0.004123513586819172\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 80 loss: 0.004123467952013016\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 90 loss: 0.00412338599562645\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 100 loss: 0.004123321268707514\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 110 loss: 0.004123368300497532\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 120 loss: 0.004123364575207233\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 130 loss: 0.0041233450174331665\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 140 loss: 0.004123356658965349\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 150 loss: 0.0041233510710299015\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 160 loss: 0.004123433493077755\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 170 loss: 0.004123376682400703\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 180 loss: 0.004123390652239323\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 190 loss: 0.004123388789594173\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 200 loss: 0.0041233813390135765\n",
            "batch 0 loss: 0.040948379784822464\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 10 loss: 0.03883109241724014\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 20 loss: 0.03851135075092316\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 30 loss: 0.03842054679989815\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 40 loss: 0.03838878124952316\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 50 loss: 0.038363244384527206\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 60 loss: 0.03835691511631012\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 70 loss: 0.03836483880877495\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 80 loss: 0.03835190460085869\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 90 loss: 0.038350921124219894\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 100 loss: 0.03835089132189751\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 110 loss: 0.038362838327884674\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 120 loss: 0.03836635872721672\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 130 loss: 0.038350362330675125\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 140 loss: 0.038345955312252045\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 150 loss: 0.03834765404462814\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 160 loss: 0.0383518747985363\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 170 loss: 0.03834385797381401\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 180 loss: 0.038359228521585464\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 190 loss: 0.03834528475999832\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 200 loss: 0.038346067070961\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 210 loss: 0.038355134427547455\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 220 loss: 0.03834662586450577\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 230 loss: 0.038353435695171356\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 240 loss: 0.03834633529186249\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 250 loss: 0.038353048264980316\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 260 loss: 0.03835660219192505\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 270 loss: 0.03835126757621765\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 280 loss: 0.038357026875019073\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 290 loss: 0.038358423858881\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 300 loss: 0.038346245884895325\n",
            "batch 0 loss: 0.3555664122104645\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "batch 10 loss: 0.2358153611421585\n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "batch 20 loss: 0.21601764857769012\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "batch 30 loss: 0.21025457978248596\n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 40 loss: 0.21451634168624878\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 50 loss: 0.2091321051120758\n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "batch 60 loss: 0.2075122594833374\n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 70 loss: 0.2090962678194046\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 80 loss: 0.20893332362174988\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "batch 90 loss: 0.20647257566452026\n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 100 loss: 0.2066512256860733\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 110 loss: 0.20796847343444824\n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 120 loss: 0.20521169900894165\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "batch 130 loss: 0.2049965113401413\n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 140 loss: 0.20557288825511932\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 150 loss: 0.20673128962516785\n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 160 loss: 0.2045709192752838\n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 170 loss: 0.2054527997970581\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 180 loss: 0.20483115315437317\n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "batch 190 loss: 0.20413365960121155\n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "batch 200 loss: 0.20440855622291565\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "batch 210 loss: 0.2048080861568451\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 220 loss: 0.20606903731822968\n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "batch 230 loss: 0.2049260139465332\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "batch 240 loss: 0.20585854351520538\n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 250 loss: 0.2077646106481552\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "batch 260 loss: 0.2054586559534073\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 270 loss: 0.2045750617980957\n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "batch 280 loss: 0.20542103052139282\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "batch 290 loss: 0.20637106895446777\n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 300 loss: 0.2072472870349884\n",
            "batch 0 loss: 1.1383631229400635\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 10 loss: 0.49448162317276\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 20 loss: 0.43236345052719116\n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "batch 30 loss: 0.2819731831550598\n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "batch 40 loss: 0.2662200331687927\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "batch 50 loss: 0.22953666746616364\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 60 loss: 0.22933818399906158\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 70 loss: 0.22343727946281433\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 80 loss: 0.21987950801849365\n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 90 loss: 0.2358480989933014\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 100 loss: 0.21747012436389923\n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 110 loss: 0.2262355387210846\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 120 loss: 0.2083168774843216\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 130 loss: 0.2398352324962616\n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "batch 140 loss: 0.21054023504257202\n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 150 loss: 0.2277785837650299\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 160 loss: 0.2214849293231964\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 170 loss: 0.22728708386421204\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 180 loss: 0.22421255707740784\n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "batch 190 loss: 0.22091346979141235\n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "batch 200 loss: 0.21465274691581726\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 210 loss: 0.21236169338226318\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 220 loss: 0.21685296297073364\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 230 loss: 0.20511123538017273\n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 240 loss: 0.21650253236293793\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 250 loss: 0.2102556675672531\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 260 loss: 0.2174157053232193\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "batch 270 loss: 0.2250998169183731\n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 280 loss: 0.22007501125335693\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 290 loss: 0.22407738864421844\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 300 loss: 0.21556097269058228\n",
            "batch 0 loss: 0.21222522854804993\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 10 loss: 0.20823349058628082\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 20 loss: 0.2034388780593872\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 30 loss: 0.20783106982707977\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 40 loss: 0.20164363086223602\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 50 loss: 0.2054987996816635\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 60 loss: 0.20485006272792816\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 70 loss: 0.20142315328121185\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 80 loss: 0.20015843212604523\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 90 loss: 0.20326611399650574\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 100 loss: 0.20566564798355103\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 110 loss: 0.2065667361021042\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 120 loss: 0.2010410577058792\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 130 loss: 0.20250225067138672\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 140 loss: 0.204126238822937\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 150 loss: 0.20650316774845123\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 160 loss: 0.2033836841583252\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 170 loss: 0.20218375325202942\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 180 loss: 0.20046687126159668\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 190 loss: 0.2025867998600006\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 200 loss: 0.20304696261882782\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 210 loss: 0.20496055483818054\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 220 loss: 0.20020663738250732\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 230 loss: 0.200588196516037\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 240 loss: 0.20904076099395752\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 250 loss: 0.20084767043590546\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 260 loss: 0.20849871635437012\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 270 loss: 0.20046807825565338\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 280 loss: 0.21158598363399506\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 290 loss: 0.20624254643917084\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 300 loss: 0.20259346067905426\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 310 loss: 0.19947178661823273\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 320 loss: 0.20133836567401886\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 330 loss: 0.21129630506038666\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 340 loss: 0.2081158310174942\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 350 loss: 0.21009570360183716\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 360 loss: 0.20165665447711945\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 370 loss: 0.20043347775936127\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 380 loss: 0.19920678436756134\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 390 loss: 0.20088884234428406\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 400 loss: 0.20317909121513367\n",
            "batch 0 loss: 0.2007066160440445\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 10 loss: 0.20100925862789154\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 20 loss: 0.19940108060836792\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 30 loss: 0.1999552994966507\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 40 loss: 0.19934529066085815\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 50 loss: 0.2013101428747177\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 60 loss: 0.20203004777431488\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 70 loss: 0.2000417411327362\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 80 loss: 0.19912302494049072\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 90 loss: 0.19835691154003143\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 100 loss: 0.19896289706230164\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 110 loss: 0.2011544555425644\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 120 loss: 0.20086510479450226\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "batch 130 loss: 0.20246709883213043\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 140 loss: 0.20362667739391327\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 150 loss: 0.19942115247249603\n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 160 loss: 0.19932840764522552\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 170 loss: 0.20155195891857147\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 180 loss: 0.2019704431295395\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 190 loss: 0.19931982457637787\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 200 loss: 0.19923286139965057\n",
            "batch 0 loss: 0.19889622926712036\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 10 loss: 0.19855478405952454\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 20 loss: 0.199210062623024\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 30 loss: 0.19871975481510162\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 40 loss: 0.199285626411438\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 50 loss: 0.19839826226234436\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 60 loss: 0.20198571681976318\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 70 loss: 0.2010759860277176\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 80 loss: 0.2002754658460617\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 90 loss: 0.19793513417243958\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 100 loss: 0.19858689606189728\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 110 loss: 0.19848018884658813\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 120 loss: 0.19737760722637177\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 130 loss: 0.1993885636329651\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 140 loss: 0.19930970668792725\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 150 loss: 0.2010289877653122\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 160 loss: 0.19928935170173645\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 170 loss: 0.19896937906742096\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 180 loss: 0.1973542422056198\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 190 loss: 0.19833292067050934\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 200 loss: 0.1980363428592682\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 210 loss: 0.19878028333187103\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 220 loss: 0.19778406620025635\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 230 loss: 0.1990838497877121\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 240 loss: 0.19863037765026093\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 250 loss: 0.19751238822937012\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 260 loss: 0.19726136326789856\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 270 loss: 0.19884304702281952\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 280 loss: 0.1985321342945099\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 290 loss: 0.19776393473148346\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 300 loss: 0.19799870252609253\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 310 loss: 0.19777515530586243\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 320 loss: 0.19842374324798584\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 330 loss: 0.19848717749118805\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 340 loss: 0.19923239946365356\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 350 loss: 0.19850051403045654\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 360 loss: 0.19990181922912598\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 370 loss: 0.1982104778289795\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 380 loss: 0.19821208715438843\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 390 loss: 0.19854260981082916\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 400 loss: 0.197939932346344\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 410 loss: 0.19858814775943756\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 420 loss: 0.19748620688915253\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 430 loss: 0.19898073375225067\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 440 loss: 0.19808924198150635\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 450 loss: 0.19946123659610748\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 460 loss: 0.19825249910354614\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 470 loss: 0.1978754997253418\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 480 loss: 0.19736352562904358\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 490 loss: 0.1972624659538269\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 500 loss: 0.19832706451416016\n",
            "batch 0 loss: 0.1992053985595703\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 10 loss: 0.19899146258831024\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 20 loss: 0.1984848529100418\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 30 loss: 0.19773119688034058\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 40 loss: 0.1976611316204071\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 50 loss: 0.19882623851299286\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 60 loss: 0.1996910274028778\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 70 loss: 0.19829551875591278\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 80 loss: 0.1977897584438324\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 90 loss: 0.1982463002204895\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 100 loss: 0.19891756772994995\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 110 loss: 0.19805848598480225\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 120 loss: 0.19752895832061768\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 130 loss: 0.19839465618133545\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 140 loss: 0.19761697947978973\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 150 loss: 0.19730114936828613\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 160 loss: 0.19749408960342407\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 170 loss: 0.19853876531124115\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 180 loss: 0.19747969508171082\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 190 loss: 0.19773423671722412\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 200 loss: 0.1987757533788681\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 210 loss: 0.19817328453063965\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 220 loss: 0.19898776710033417\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 230 loss: 0.19826221466064453\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 240 loss: 0.19778576493263245\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 250 loss: 0.20001903176307678\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 260 loss: 0.197628915309906\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 270 loss: 0.19782784581184387\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 280 loss: 0.1979193389415741\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 290 loss: 0.1973828673362732\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 300 loss: 0.19823521375656128\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 310 loss: 0.19737662374973297\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 320 loss: 0.1977832019329071\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 330 loss: 0.19846802949905396\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 340 loss: 0.1984822154045105\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 350 loss: 0.19868861138820648\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 360 loss: 0.19781820476055145\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 370 loss: 0.1996106207370758\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 380 loss: 0.19795694947242737\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 390 loss: 0.19775722920894623\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 400 loss: 0.19762487709522247\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 410 loss: 0.19840478897094727\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 420 loss: 0.19888466596603394\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 430 loss: 0.1984388828277588\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 440 loss: 0.19853468239307404\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 450 loss: 0.19781169295310974\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 460 loss: 0.1985360085964203\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 470 loss: 0.19808237254619598\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 480 loss: 0.19839367270469666\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 490 loss: 0.19814535975456238\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 500 loss: 0.1980641931295395\n",
            "batch 0 loss: 0.19773206114768982\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 10 loss: 0.19764646887779236\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 20 loss: 0.19736990332603455\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 30 loss: 0.19748680293560028\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 40 loss: 0.19812873005867004\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 50 loss: 0.1976635456085205\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 60 loss: 0.19818979501724243\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 70 loss: 0.19767676293849945\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 80 loss: 0.19784782826900482\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 90 loss: 0.19804824888706207\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 100 loss: 0.19852808117866516\n",
            "batch 0 loss: 0.19797801971435547\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 10 loss: 0.19809725880622864\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 20 loss: 0.19766029715538025\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 30 loss: 0.19776061177253723\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "batch 40 loss: 0.19871622323989868\n",
            "pert_predictions_np: [3 0 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 50 loss: 0.19877956807613373\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 60 loss: 0.19823966920375824\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 70 loss: 0.1975046843290329\n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 3 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 80 loss: 0.1978103220462799\n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "batch 90 loss: 0.19783815741539001\n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 3 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 0 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 2 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "pert_predictions_np: [3 3 8 3] \n",
            "batch 100 loss: 0.1983734518289566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision as TV\n",
        "inv_normalize = transforms.Normalize(\n",
        "        mean=mean,\n",
        "        std=std\n",
        "      )\n",
        "\n",
        "   \n",
        "for i in range(0,adversarial_examples.size()[0]):\n",
        "  print(inputs[i].size())\n",
        "  imshow(inputs[i])\n",
        "  inv =inputs[i] / 2 + 0.5\n",
        "  TV.utils.save_image(inv, \"/content/drive/MyDrive/TFG/CW/logs/%d_original.png\" %(i),)\n",
        "  imshow(adversarial_examples[i])\n",
        "  inv =adversarial_examples[i] / 2 + 0.5\n",
        "  TV.utils.save_image(inv, \"/content/drive/MyDrive/TFG/CW/logs/%d_adversarial.png\" %(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fGs6Ihqb_P2p",
        "outputId": "91666ce8-5761-4925-980f-60fbc1a223a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAb1klEQVR4nO2da4ycZ3XH/2eue/E6TrDjuI5zJSgNJDhhG4KAioJAaYQUkKoIVKEgRRhVRCoS/RClUkmlfoCqgPhQUZkmIlQ0l3IRURW1pBE0JYSAQxLHwSUkjpPYWXt9313vzv30w0zKJnr+Z3dnd2dNnv9Psjz7nnne97zPvGfemec/5xxzdwgh3vwU1toBIcRgULALkQkKdiEyQcEuRCYo2IXIBAW7EJlQWs5gM7sewNcBFAH8s7t/KXr+xo0b/cILL+znSP241x/WhxQ5YPXSbGXnoxPZAmk2Um1XekqKwSkX+pqP/jyMzrkT2QJjP/I3O+dXXnkZx48dTRr7DnYzKwL4RwAfBnAAwC/N7AF3/zUbc+GFF+JnP3uc7C88WHpz7F9gjQa2A2Pa1m7zY3mHf3gqBJ+rCgW+z5UO9kZgm2vzC7HW4G8TbFg7eNWKQQCeVaYmDJWL3EgPx32Pgq/R5i9arRnMVa1Jbc0GsQWvc5Wc8w0fej8ds5yP8dcCeN7d97l7A8C9AG5cxv6EEKvIcoJ9K4BX5v19oLdNCHEGsuoLdGa2w8x2mdmuI0eOrvbhhBCE5QT7QQDb5v19fm/b63D3ne4+7u7jmzZtXMbhhBDLYTnB/ksAl5nZxWZWAfAJAA+sjFtCiJWm79V4d2+Z2a0A/hNd6e0ud382HmXwYvqQwaIvXbUuBYuw0btY+A7nfDWeLdJ6INe1Onx/nWhlmsxT1xaceB8MBbZKcKixCrexte5I5os0hmAxvk9hlp9Yq8O9nAuki+m5Fh83x1fjW630uGKB+9j29FUcyX/L0tnd/UEADy5nH0KIwaBf0AmRCQp2ITJBwS5EJijYhcgEBbsQmbCs1fil0u44pk4zCYJrBm0ihQxVufvDZS7IVArBsYgMAoBmxBUK3A/vcK2m2eIST5TrUogyaPqCy4OF4HWxQPQych+JPef76/SbR+dLF+aaQUJLI0p2afB5nKvz64pJbwAfU2um4yiSDXVnFyITFOxCZIKCXYhMULALkQkKdiEyYaCr8R13NBr1pC0qw9Rqplc5vc1XP22Iv48Vh6IMmqWnXFjge6EcJNbUua0dnFsnWHHlSTLRanZkCxSD4F5hnh7XDlbHPfDDAz/aQRZVmyxom/FLPxJkonJxkUhSrfDrykmyVKPJlZwOKYXmQSaM7uxCZIKCXYhMULALkQkKdiEyQcEuRCYo2IXIhIFKb8WCYWyYFC6LNI2oEBohkmpOBwkLjUAOKxXT8snIaCBBlXmhtlIgGUXyWqPBJZlSKf2SRnXr+mufFAt2LHmpHiT/RNJbJGu1gn02aul9tkgiCQA0m8G1E4xrMJ0PCDObSgWS6DVSpWNYjcJiMehARC1CiDcVCnYhMkHBLkQmKNiFyAQFuxCZoGAXIhOWJb2Z2X4A0+gWMWu5+3j0/K70lpavWq0oyytt6wQZPo1AF5olWXQAMHua21hNsJbxBkrrRvkUV6pcWukEqVceyJTcFmWUccz6a6TF2l61g9fMAn0tkt5KgdzULqaP1wzk10KQEVcuBrJtM6ozxyU7I7Lc8NA6OoZJedGrtRI6+5+4u3oxC3GGo4/xQmTCcoPdAfzIzJ4wsx0r4ZAQYnVY7sf497n7QTM7F8BDZva/7v7I/Cf03gR2AMAFF1ywzMMJIfplWXd2dz/Y+38SwA8AXJt4zk53H3f38U2bNi3ncEKIZdB3sJvZqJmNvfYYwEcA7Fkpx4QQK8tyPsZvBvCDnmxQAvCv7v4f0QD3btHJJEHiVYsUX4ykt2JQBHI0yACrBhlsHZKlFtWvLAUyWZG0kwKAYnnpmX4xUbYZJ5LKIqmpQwpLlsu88GIkrxWCC6RYju5Z6fOu1XjmYNvTRVEBoE0kRQDokCKbANBocOmNJTiacT/KlXQ2JY0vLCPY3X0fgHf2O14IMVgkvQmRCQp2ITJBwS5EJijYhcgEBbsQmTDQgpOtVguTR04kbZEkw4oosgKQAFAuBRlUgeTVKXL5hO4vessMsvk88rEYaJGRVkZot/l5NdtcFqoHGYLe4fLgzMxscvvp2VN0zNatm6lteHiE2hD0j2OvTbHEJ3GuNkdtMzOnqS0qptkM5tE8PY/1GpfemFwXZUTqzi5EJijYhcgEBbsQmaBgFyITFOxCZMJAV+ObzTZenTiediRITqmQH/1Xh3jtt+ER3napMsTf4ypBuya2Qh6tdEdUgmX8QDBAmyQGAUC9nk7wqJHtAOBBcsf0VHpVHQAOvHKI2h577PHk9lcOvEjHfPrTf05t17xrO7VF6oSRhKj1Y7y+W9Qqi+0PiOsoNhtB0lAnvc/Z2RodM318Orm9HdQu1J1diExQsAuRCQp2ITJBwS5EJijYhcgEBbsQmTBQ6a3d7uDUdDrJoFjgckexmJaNymWeKFCqcomkPMzf46KEHCbJRMkH0f7KJW5rRy2q5niiRr2enpNmkye7nDyWlkMB4JmnnqG2J3btprYjR44ltxeCRKOf/ORRaotk1i1beAJNsZi+xFnLpYVs60eHg2Pxcax+IQCcOjmTHsPVUhRI4cOo9qLu7EJkgoJdiExQsAuRCQp2ITJBwS5EJijYhciEBaU3M7sLwEcBTLr7O3rbzgFwH4CLAOwHcJO7p4vLzcMBNFtpCaLhXGdgUkglyDYrtANppcnHRbJLicg4hSJ/z4wkxUKQLNdo8Pmo1Xg21PHjaRlt/36ebbZnN5fQntv7PLXBuXS4fv1Zye2NJs+ie+yxn1NbVLvummuuprYrr7wyuX39+vV0TCSXjg7zrEjv8IyzqAbdWRvGktuHhrjM1yatpkplHtKLubN/C8D1b9h2G4CH3f0yAA/3/hZCnMEsGOy9futvvF3cCODu3uO7AXxshf0SQqww/X5n3+zuE73Hh9Dt6CqEOINZ9gKdd38rSn8LaGY7zGyXme06dXLBr/VCiFWi32A/bGZbAKD3/yR7orvvdPdxdx8/a8PZfR5OCLFc+g32BwDc3Ht8M4Afrow7QojVYjHS2z0APgBgo5kdAPBFAF8CcL+Z3QLgJQA3Le5wDhTTn/gNS89CagVSR6EVSGgWtF0KikBOB61/KEFGnLW5vFYN5J/nfvMbanvyySeT21944QU65tixo9QG0poIACrlUWqbmjqZ3F6rpzO8AGDiEJfXTs/yr4Avv/wStbEswPe85zo6ptXi8lozknSDjl0s+w4ACiT7sTzMr4ECkd4suH4XDHZ3/yQxfWihsUKIMwf9gk6ITFCwC5EJCnYhMkHBLkQmKNiFyISBFpyEgaZ6lUvcFSZe1YLCi50al7xaQd+tw4cPU9tzv30uuX3Txk10zIYNPLtq+jg/ViFo9rYvkNGefz6dpTZ7mmebIZAAC6VAhmry+Z85nS5w2W7zMa02z+Y7cYJLb6Xg2nnwwQeT26PMweuueze1Da/nPeIQFHssBxImLJ0RV68tPYsu6juoO7sQmaBgFyITFOxCZIKCXYhMULALkQkKdiEyYaDSW6PRxCsvH0zaykGhvEYjLeNMTfEsqWadSxBBshwOHnyZ2v77f36S3L5581vomKuuvILaDr28j9qmAqnpxMl0RhkATE6m5bwg+Q5B7RGsG+PSYbHIZTm00pPsbd6fDx1elLE+G8isLT7u5RfTGXHfve9+OmZmaorarr5unNrGzt5AbVasUluNXKszp/lctckpN5pBJii1CCHeVCjYhcgEBbsQmaBgFyITFOxCZMJAV+Pr9Tpe2rd/yeOaZIXRSR0uACgYr99VqfC2On+wdQu1XX75W5PbD00eoGP2vbiX2mZPcDWhFqw+Hz16hNpOkpX6YpEnYpQC21CZr7gXqsESP5E8rM1Xiy14PZt1nqxz9DAtboxKJe3/iWPH6Jj77rmX2h79+aPUdvW7/4ja/vDt26mtMkJaZQV1FNukFl6nw18T3dmFyAQFuxCZoGAXIhMU7EJkgoJdiExQsAuRCYtp/3QXgI8CmHT3d/S23QHgMwBe04Bud/d0sa/5+4KjjHRSS9A5B0PV9HtSscSTC0pBkkbUiqdI2lMBwDvednF6TCdoaTTBE2sQSCsIJJR1I1w6LOAcYuH763QCCTO4HbRb6dcSADokUyOSSy3wsR0kyUxNcwlzZGQkvT+SqAMAxwJp8+hxLvM988wearv0rZdT2/s/8OHk9vO3XULHVEfTtfBCOZpafse3AFyf2P41d9/e+7dgoAsh1pYFg93dHwFwfAC+CCFWkeV8Z7/VzHab2V1mpsbrQpzh9Bvs3wBwKYDtACYAfIU90cx2mNkuM9s1e7qPlsdCiBWhr2B398Pu3vbuasA3AVwbPHenu4+7+/jIKO/nLYRYXfoKdjObny3ycQB8GVIIcUawGOntHgAfALDRzA4A+CKAD5jZdnT1nP0APruYgzXrNby6L50FNjXN634xIskoUGrgnUDyIq14AKBWS38NOXmKZ1DNkTFdP3i2WTOoqxZ9HWLtfyxU+bjkVa/z7LtIzmO7jKShyMl24GMn2Ge9nm57FbWMGhsbo7bREd7+af36dPYaAIwEcu/B59PtvKYn+bp4uTqU3F4Lro0Fg93dP5nYfOdC44QQZxb6BZ0QmaBgFyITFOxCZIKCXYhMULALkQkDLTjZbNRx+OCLSduLL6a3A0CLZFA1m7wIYaPOs5rabS7jjI+/i9o2nZ2WZE4eO0THbBjmPyQa28DbRrWIhAYAjRpvC+REDjt5imeGnQzaaBUCiWp6epramCw6PBxk7BX5vceCopiVapThmB5XqfCMyfPOO4/aCsb92DDG2z9VK2mpDAAOH0i3qNp79Gk6pkSkvJlAwtadXYhMULALkQkKdiEyQcEuRCYo2IXIBAW7EJkwUOltaKiKt70t3S9t27atdFyjmS5sWJvjGVkzMzz7Z3YmnQkFABdccD61nX12uiBPI+hDtvX8bdS2fv16amsHGX0eZIAVSObYxASXB1+d5LZqUNzy2WefpbbTJPvq3HM38mMNcTmsSgpHAsDQMJe1Tp5I976bmeFFQieD+Wi1+NyfGOVSZDXIevNmWlqeCuTSoXJ6rqJCmrqzC5EJCnYhMkHBLkQmKNiFyAQFuxCZMNDVeLMCrZ1VHeKrvkWSjOFRDbpgxbod1HcrFPiU1OppVWCuwVdAazXeIml0lPtRDJJCCha8R5PV+HM38aSb0fU8WccDPyYmDlLb0FA6OWVslK+qd4KadmNj3MfqEF+NL5fTiSvrgv0NBaoAjNuC3CWctY7XtZs6nq4112hwtcmdXDsWKDXUIoR4U6FgFyITFOxCZIKCXYhMULALkQkKdiEyYTHtn7YB+DaAzej2+9np7l83s3MA3AfgInRbQN3k7ieifbU7HZycYXIClwzK5bSMEyWEhK2JwiQTXt+N1cI7coKfdoH4DgDlKq9nVijwVkisrlpks6C1UqlSprZW0EerUubjWKrR2Fk8+efoMd5G66wgaYglKEVEdeuGiDwMAI02n8d6UPewHNXXQ3qOC/xlpu2r9u57jo5ZzJ29BeAL7n4FgOsAfM7MrgBwG4CH3f0yAA/3/hZCnKEsGOzuPuHuv+o9ngawF8BWADcCuLv3tLsBfGy1nBRCLJ8lfWc3s4sAXA3gcQCb3X2iZzqE7sd8IcQZyqKD3czWAfgegM+7++uKU3v3y3PyS7KZ7TCzXWa2a65WW5azQoj+WVSwm1kZ3UD/jrt/v7f5sJlt6dm3AJhMjXX3ne4+7u7jw8FvmIUQq8uCwW7dZdw7Aex196/OMz0A4Obe45sB/HDl3RNCrBSLyXp7L4BPAXjGzJ7qbbsdwJcA3G9mtwB4CcBNC+2o0Wzh4OGjSVurGdTOKqTfk9ptPqbDsoIQZAwBaAepS20ivR07la5zBgCzDf7VZWaW1xhD4KMFLYioLMcVo7BuWZPU/wOAg6++Sm1M6mOvJQCUA0mxEJxAtcQlQCbAloLMwU6QFVkM5n5kmMt5rB0WAGw+L73ctencTdwPMo+Vnz1KxywY7O7+U/BL5UMLjRdCnBnoF3RCZIKCXYhMULALkQkKdiEyQcEuRCYMtOBkl/TCPmvxBADNBmn/VOeyVse5nAT011qJSW/NFvfd5/j+Jg7xDLs4My+obNgH0f7YOQNAvc79HxtLF1g8dIi3VhoNilHWg19fnjo1RW2lUloq6ydzEAA8kN6iNLUo65DZhoIfobEx0XF0ZxciExTsQmSCgl2ITFCwC5EJCnYhMkHBLkQmDFR6KxYKGBlJyyuh3EHksCjrrdlqUFsjyESLpKZGI73PKJMrkvIKgS2S3iIfW0EGG/UjkIwi/4eHeX8+xnHS1wyIzyuSlKamuPS2bt265HYmDQJApcKz11qB6ulBJl00j+WgcCeDXXPh9bbkowghfi9RsAuRCQp2ITJBwS5EJijYhciEga7GF4LV+GhFkq3URyuPTlrqAEArWKmPkjvYanxUpy2qrefB6nM72GeYNERs0XnV66wlVzxX0Qo5W1mPVJdISZienqG2uTmurtRq6XM7ffo0HVMOVuNLlSA5JVA1ohV+NifRfJRJ+6cI3dmFyAQFuxCZoGAXIhMU7EJkgoJdiExQsAuRCQuu35vZNgDfRrclswPY6e5fN7M7AHwGwJHeU2939wcX2BeV2EqBlMBsUUudTofLFq1S0IIokADZ8SKJJLTVli6hAbGcV5ubTW6PytYVi9F7PpeaIumTEc1vtVoNbFy6qlT4OFbHLbzeypEt8GOIJwZF9eTYnEQJVghkT8ZixLoWgC+4+6/MbAzAE2b2UM/2NXf/hyUfVQgxcBbT620CwETv8bSZ7QWwdbUdE0KsLEv6zm5mFwG4GsDjvU23mtluM7vLzM5eYd+EECvIooPdzNYB+B6Az7v7FIBvALgUwHZ07/xfIeN2mNkuM9s1R366KIRYfRYV7GZWRjfQv+Pu3wcAdz/s7m3vdhj4JoBrU2Pdfae7j7v7+HCwgCGEWF0WDHbrZjvcCWCvu3913vYt8572cQB7Vt49IcRKsZjV+PcC+BSAZ8zsqd622wF80sy2oyvH7Qfw2YV2ZIUCKkReiWquMWmi0eQZWVGxsJLx0+6nFl4/ch0AoBpkjQWSXTOQ3hojo8ntY+v5koqDy3xdMYZYAh/Za1MIJKNSic9jJJVFkh2rkzdMsi8BYCjYX9T+yYrcx0hGY9mD0RhmizIRF7Ma/1OkG7SFmroQ4sxCv6ATIhMU7EJkgoJdiExQsAuRCQp2ITJhoAUnh4dHcNVV25O2QpB51emkixdOTZ2iY44cmaS20zO8XVAolSEtvcXZX9xmHX7O7XbQ/imQvNrttNTUCXzsdLj05t6v9JbeZyS9hW20qCUuvsik3mqVZ6FVhrj0hkB66wTnZklBq4uTs2tHLcCITe2fhBAKdiFyQcEuRCYo2IXIBAW7EJmgYBciEwYuvb39qmuStqi2npPMK9bHCwAOvfoqtb3w3HPUdvzEUWpjEiCwdLkOANy5HFPs8JfGg5fNO0svAsnPC2hHtha3DQXjGGGBxYAoU7FEMtGsFPScC15Oi1yMakAWAiN5yZgkBwBMYYtefd3ZhcgEBbsQmaBgFyITFOxCZIKCXYhMULALkQkDld4cjjaRhqKsLJYRNzK6jo65+OJLqG2UFCEEgKeeeoLaTp06mdxeCKSfSJbrtCOtJsiSCuaqn/5r7vwyaLcD6a0Y2Mi4yL+oWGJkC8+ZjuP764TyJT9nCzLioivEWPHIYAy7T0fzpDu7EJmgYBciExTsQmSCgl2ITFCwC5EJC67Gm9kQgEcAVHvP/667f9HMLgZwL4C3AHgCwKfcPejH1P3xfqOeTmoJOuegMVtLbh8Z5avq1aAu2datvL381FR6xR0A9uzZndxeKESrwUHtt6DuXpjRENDfanxUny6ogxas1LNxcY0/TrTK3A/9tGMCAItesz73yVs58UPR1fglj3g9dQAfdPd3otue+Xozuw7AlwF8zd3fCuAEgFsWsS8hxBqxYLB7l5nen+XePwfwQQDf7W2/G8DHVsVDIcSKsNj+7MVeB9dJAA8BeAHASf9dneEDAPhnYyHEmrOoYHf3trtvB3A+gGsBXL7YA5jZDjPbZWa7Tp080aebQojlsqTVeHc/CeDHAN4DYIPZ/zc6Px/AQTJmp7uPu/v4WRt4j3AhxOqyYLCb2SYz29B7PAzgwwD2ohv0f9Z72s0AfrhaTgohls9iEmG2ALjbur/yLwC4393/3cx+DeBeM/s7AE8CuHOhHbVaLRw7lv4oPzY2QsfVG2nprd6o0zFv2bCe2krBW9zGjRupbZgk0MzOziS3A0AhyIAoRAXNopJlfSST9JuA0i9MTopaRkVSXtjWqA/JKzrnqKZdJK8FJQVDojnhLP11XjDY3X03gKsT2/eh+/1dCPF7gH5BJ0QmKNiFyAQFuxCZoGAXIhMU7EJkgvWTJdX3wcyOAHip9+dGALzX0uCQH69Hfrye3zc/LnT3TSnDQIP9dQc22+Xu42tycPkhPzL0Qx/jhcgEBbsQmbCWwb5zDY89H/nxeuTH63nT+LFm39mFEINFH+OFyIQ1CXYzu97MfmNmz5vZbWvhQ8+P/Wb2jJk9ZWa7Bnjcu8xs0sz2zNt2jpk9ZGa/7f2/6sn/xI87zOxgb06eMrMbBuDHNjP7sZn92syeNbO/7G0f6JwEfgx0TsxsyMx+YWZP9/z42972i83s8V7c3GdmlSXt2N0H+g/dtlcvALgEQAXA0wCuGLQfPV/2A9i4Bsf9YwDXANgzb9vfA7it9/g2AF9eIz/uAPBXA56PLQCu6T0eA/AcgCsGPSeBHwOdE3TzV9f1HpcBPA7gOgD3A/hEb/s/AfiLpex3Le7s1wJ43t33ebf09L0AblwDP9YMd38EwPE3bL4R3cKdwIAKeBI/Bo67T7j7r3qPp9EtjrIVA56TwI+B4l1WvMjrWgT7VgCvzPt7LYtVOoAfmdkTZrZjjXx4jc3uPtF7fAjA5jX05VYz2937mD/QWmJmdhG69RMexxrOyRv8AAY8J6tR5DX3Bbr3ufs1AP4UwOfM7I/X2iGg+86OvttELJtvALgU3R4BEwC+MqgDm9k6AN8D8Hl3n5pvG+ScJPwY+Jz4Moq8MtYi2A8C2Dbvb1qscrVx94O9/ycB/ABrW3nnsJltAYDe/5Nr4YS7H+5daB0A38SA5sTMyugG2Hfc/fu9zQOfk5QfazUnvWMvucgrYy2C/ZcALuutLFYAfALAA4N2wsxGzWzstccAPgJgTzxqVXkA3cKdwBoW8HwtuHp8HAOYE+sWhLsTwF53/+o800DnhPkx6DlZtSKvg1phfMNq4w3ornS+AOCv18iHS9BVAp4G8Owg/QBwD7ofB5vofve6Bd2eeQ8D+C2A/wJwzhr58S8AngGwG91g2zIAP96H7kf03QCe6v27YdBzEvgx0DkBcBW6RVx3o/vG8jfzrtlfAHgewL8BqC5lv/oFnRCZkPsCnRDZoGAXIhMU7EJkgoJdiExQsAuRCQp2ITJBwS5EJijYhciE/wNF4CzTEU/JgAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYxElEQVR4nO2dfYyVZ5nGr1s6MMDAwPAxjAMthaUuWBdaB8KmxrhtNKw1VuOm6h+miY2YjU3WxP2j6SZrN9k/dONHNNm04raxblwrq63WtdmVbWtQU1oHGGAEyjeW6ZThY4ChSPmYe/84L5tpfe9rzjwzc860z/VLCGee+zzv+5znnOu85zzXue/H3B1CiLc/76j3AIQQtUFiFyITJHYhMkFiFyITJHYhMkFiFyITrhtNZzNbB+BbACYB+Dd3/wq7f3Nzsy9YsCA6FjtPafvVq1fDPsxSZOeaNGnSiPux473jHfH7KTvXlStXwtjZs2fD2OXLl0vbp0+fHvaZNWtWGGOk2LasT6oNPDg4OOJjsnOx4zHYcxY9LwDwxz/+sbT9woULI+5z9epVDA4Olr4gk8VuZpMA/CuADwI4BuB3ZvaUu++O+ixYsAAPP/xwaYy98BsaGkrbz58/H/a5ePHiiI8HAM3NzWFs8uTJI2oHgKampjA2c+bMMHby5Mkw9vOf/zyMvfrqq6Xta9asCft89KMfDWPsjYy92UYxJiR2PNaPPddRLEV8AH+T6O/vD2PHjh0LY93d3aXt27ZtC/vs2bOntJ29bkbzMX4NgAPufsjdLwF4HMBdozieEGIcGY3Y2wG8POTvY0WbEGICMu4LdGa23sw6zayTfdcUQowvoxF7D4BFQ/5eWLS9AXff4O4d7t7Bvg8LIcaX0Yj9dwCWmdmNZjYZwKcAPDU2wxJCjDXJq/HufsXM7gPwP6hYb4+6+++H6ROugrIV0MbGxtJ2ZhmxlXq26vv666+HsWhF+Ny5c2Ef9tWFrdB2dXWFscOHD4exaIxs9ZmtZjOXJAW2qs6sq1RbK1o9v+66+KXP3BoG++QavYYBoL29fKlr9erVYZ+jR4+Wtn/7298O+4zKZ3f3pwE8PZpjCCFqg35BJ0QmSOxCZILELkQmSOxCZILELkQmjGo1fqQMDg6GNg+zQiI7bMqUKWEflmQyMDAQxg4cOBDGtm/fXtoeJZ8AQFtbWxibPXt2GDt48GAYe+2118LY9ddfX9p+0003hX1Ss7xSbLnULECWgMJeB9FjY8djiU3MAmTjZwlRUUbi/Pnzwz7Ra2fatGlhH13ZhcgEiV2ITJDYhcgEiV2ITJDYhciEmq/GRyvhbDU+Wm1lCSi7d4fVsbBjx44wtnXr1jDW29tb2s4Sa6LVcQBYtWpVGGOJQYcOHQpjK1euLG2Pav8BfIWZPS9sZT2aE3Yu5gqwc7FEmIhLly6FsdSagmwcbB6j1X/mMkSr8cwR0JVdiEyQ2IXIBIldiEyQ2IXIBIldiEyQ2IXIhJpabxcvXsS+fftKY3Pnzg37RdvgnD59Ouzz0ksvhbG9e/eGMWbJpNQzO3XqVBjr6fmTYrz/D5uPX/3qV2EsSpJhNg5LCmHzwWy0yHpj52K2ERsHqzcYHZOdi1m6qdtXpcwj6xNZgNQ2DCNCiLcVErsQmSCxC5EJErsQmSCxC5EJErsQmTAq683MjgAYAHAVwBV372D37+/vx8aNG0tjrGZclG3GtmpatGhRGDtx4kQYY3ZHlJXFtvZhMZaZt3z58qRjPvnkk6Xtt99+e9jntttuC2Nsa6gUq4lZQyxrjGUWpmTmpW4nxfqlZsRFNiCb+2g+6DyFker5K3c/OQbHEUKMI/oYL0QmjFbsDuCXZrbVzNaPxYCEEOPDaD/Gv8/de8xsPoBNZrbX3TcPvUPxJrAe4N+thBDjy6iu7O7eU/zfB+BJAGtK7rPB3TvcvUNiF6J+JIvdzKab2YxrtwF8CED3WA1MCDG2jOZS2wrgycJKuQ7Af7j7f7MOFy9epBlnI4XZOMwiibLohusXWU3MVkm1Y3bt2hXG2Cekw4cPl7Y/9NBDYR9m87Hsu5Q5Zn2Y7ZlSkJT1S33OmLXFrGD2uKPxswKcKVmFyWJ390MAykuZCiEmHLLehMgEiV2ITJDYhcgEiV2ITJDYhciEmv/KJbI1Ghoawj4p+4ZFe8oB3Kphdl5kazA75syZMyM+HsD3eps3b14Yi6yy/v7+sE9XV1cYYxlxKQUn2eNix2MZYOyYM2bMKG2PCnMC3JplhSrpPmsJdh57LUb7w6ngpBBCYhciFyR2ITJBYhciEyR2ITKh5qvx0Y/7UxITUhNhWD8Wi5Iq2LlYMgNzIFiduZT6acePHw/7PPHEE2GMrTAvWbIkjEWr52zlnD3mlKQQIE5OSa13F62CAzyRhx0zxaFiTk54nhH3EEK8JZHYhcgEiV2ITJDYhcgEiV2ITJDYhciECVPuNcUOY32YVZNa6yw6ZmpyBLPQTp8+HcZYUsW0adNK20+ejDft2bJlSxhj41+9evWIx8Hmd+rUqWFs1qxZYYwlNkUwC3Csbb7hYtHjZnOfUoNOV3YhMkFiFyITJHYhMkFiFyITJHYhMkFiFyIThrXezOxRAB8B0OfuNxdtLQB+BGAxgCMA7nb3uMhZFTC7I7LYUjJ/hoNunxPYRswiYbXTmI2TSsqcMJtv06ZNYay7O97ab82aP9njEwB/nllGWWtraxibOXNmGJs9e/aIx8Gel+nTp4cxVteOZdlFNQXZcxmNkT2uaq7s3wOw7k1t9wN4xt2XAXim+FsIMYEZVuzFfutvfuu/C8Bjxe3HAHxsjMclhBhjUr+zt7p7b3H7VVR2dBVCTGBG/XNZd3czC79cmNl6AOtHex4hxOhIvbIfN7M2ACj+74vu6O4b3L3D3TsSzyWEGANSxf4UgHuK2/cA+NnYDEcIMV5UY739EMAHAMw1s2MAvgzgKwA2mtm9AI4CuLvaE0Y2VYoNlVo4MtV2iY7JLKOUbX+Gg43//Pnzpe0phTQBXvSQWU0HDx4sbY+y4QCemceKUbJsuaamptJ29pyx+WXjYMdk8xhtzcUsxWgcLJNyWLG7+6eD0B3D9RVCTBz0CzohMkFiFyITJHYhMkFiFyITJHYhMqGmBSfNLLQnWAHA1HNFMBuEZSdFlgyzrlgxRGbVsEy6yF4D4kwpZhktX748jC1YsCCMXbhwIYxFdtKpU6fCPszKY7D5j2CWKIM9L+x1xcYY2YOsyGaUfcdeG7qyC5EJErsQmSCxC5EJErsQmSCxC5EJErsQmTBh9npjRJZXasHJlL3BgNiWY3YdO9fixYvDGLPKtm3bFsaifexuuOGGsA/bh2z37t1hjFlvKXPFuP7668MYs22jMTILjdm2zLJLzcKMLNiXX3457BPB7Etd2YXIBIldiEyQ2IXIBIldiEyQ2IXIhLfEanwKbKWe1elKWW1lSQ5Lly4NY+3t7WEsJSEHiLc7ilbpAeCVV14JY2ylns1VNMcs+efd7353GGPOxa9//eswFiXkpCatsFV8FmNzFcXYazjqQ1/bYUQI8bZCYhciEyR2ITJBYhciEyR2ITJBYhciE6rZ/ulRAB8B0OfuNxdtDwL4HIATxd0ecPenqzhWaBmkWF7M6mD2FLO12DiimmDvete7wj533nlnGDt79mwY6+7uDmPz5s0LY1FSyJEjR8I+qdtQseSOqEYaS2hZuHBhGEtNXooeW+pjZq8PZpWlJslEpGyjVs2V/XsA1pW0f9PdVxX/hhW6EKK+DCt2d98M4HQNxiKEGEdG8539PjPbaWaPmln5z7aEEBOGVLE/BGApgFUAegF8Pbqjma03s04z60wtNiGEGD1JYnf34+5+1d0HAXwXwBpy3w3u3uHuHSkLEUKIsSFJ7GbWNuTPjwOIl46FEBOCaqy3HwL4AIC5ZnYMwJcBfMDMVgFwAEcAfL7aE0ZXd5aFFH38T93Ch8EynqLztbS0hH2YTTZz5swwdvjw4TDGMsB27NhR2s4sGWZrzZkzJ4zNmDFjxP3Y2Nm52DZUe/fuDWPRdkgsm4993WSWLmOsv8KmWIfDit3dP13S/MiIzySEqCv6BZ0QmSCxC5EJErsQmSCxC5EJErsQmVDTgpPuHhbES8kYYjYIi6XaIAMDA6XtrGAji61duzaM9fT0hLEXX3wxjKVYMswevOOOO8JYb29vGOvr6yttv+WWW8I+zMJctmxZGGM2WlSAc9++fWEfNvep2WssQzOyndlrOHrMtEhlGBFCvK2Q2IXIBIldiEyQ2IXIBIldiEyQ2IXIhJrv9RZZQyl2WGrxv1TLLjrfyZMnwz4XL14MY3Pnzg1jp06dCmORBQikZQgy64rtv3bjjTeGsT/84Q+l7UuWLAn7sCzACxcuhLHW1tYw9t73vre0PSoeCgDPPvtsGGPZmU1NTWGssbExjEXWJytIeujQodJ2Nk+6sguRCRK7EJkgsQuRCRK7EJkgsQuRCTVdjTczTJ48uTTGVjmj1WeWXBAl3IyGaKWbnStKxACALVu2JMVSHAM2v2wFd+rUqWHsk5/8ZBiLHIoDBw6EfaIVfICvZrP5WLp0aWk7q2l34sSJMBZtrwUAzc3NYYyt1EcuxLlz58I+Efv37w9jurILkQkSuxCZILELkQkSuxCZILELkQkSuxCZUM32T4sAfB9AKyrbPW1w92+ZWQuAHwFYjMoWUHe7e/8wxwotoMuXL9N+ZTDLK3WbnpQaYyyhZfr06WHsF7/4RRg7duxYGGOWYzQWZq+xZJ3NmzeHsXe+851h7D3veU9pO3vOmNUUbeMEAO3t7WEsStZh9fM6OjrCGKtdF9nKALcwo3p97DEvWrSotP3o0aNhn2qu7FcAfMndVwBYC+ALZrYCwP0AnnH3ZQCeKf4WQkxQhhW7u/e6+7bi9gCAPQDaAdwF4LHibo8B+Nh4DVIIMXpG9J3dzBYDuAXACwBa3f3aZ6FXUfmYL4SYoFT9c1kzawLwEwBfdPdzQ7+/urubWelvSc1sPYD1xe3RjVYIkUxVV3Yza0BF6D9w9yeK5uNm1lbE2wCUrjK4+wZ373D3jvHYT10IUR3Dqs8ql+NHAOxx928MCT0F4J7i9j0Afjb2wxNCjBXVfIy/DcBnAOwys66i7QEAXwGw0czuBXAUwN3VnDD6KH/p0qWwT2SjpdprDFa7LrK8Fi9eHPZh2zGxWGStAMCUKVPC2Jw5c0rbma3FbL7nn38+jLG5OnPmTGn7b3/727APq7t3/PjxMPbZz342jK1evbq0nVmizKZk9QZfe+21MMbs0iirk72+I5uPfVUeVuzu/hsA0RHijcCEEBMKfYkWIhMkdiEyQWIXIhMkdiEyQWIXIhNqXnAysiBYNlQtf3nHzrVw4cLSdralUWRBAcCKFSvC2KpVq8JYZK8B8bZG7HGxIops/C0tLWFs2rRppe1RNhzALUBmNzIbbf78+aXt7PXGfvzV3d0dxrZv3x7Gosw2ILYVmV0XZSqyrbx0ZRciEyR2ITJBYhciEyR2ITJBYhciEyR2ITKhptbb4OBgaA0wu4NlV6XAzsWKBt50002l7TfffHPYhxUAZHYSs7VaW+OiQJENxR7XddfFLwM2RhaLzrds2bKwD8sCZBbgypUrw1jK3neRXQcAn/jEJ8IYs0vZ+KPHzQqBRhlxX/va18I+urILkQkSuxCZILELkQkSuxCZILELkQk1T4SJVkEbGxvDfqy2VwpsdT9K4ACAmTNnlrazWmGzZ89OGkeqOxHV8mMr3Wz8bNsidkxWxy2Frq6uMMYSeaIV8hkzZoR92Mo5e16WLl0axlJqG6bwne98J4zpyi5EJkjsQmSCxC5EJkjsQmSCxC5EJkjsQmTCsNabmS0C8H1UtmR2ABvc/Vtm9iCAzwE4Udz1AXd/mh2rsbERy5cvL40dPnw47BdZb6yuWmrdOpYgcfny5dL2LVu2hH3Wrl0bxu68884w1tnZGcYOHjwYxiIbh1mbLKGF2Wtsy65oHCy5g9l8zc3NYWzz5s1hrKenp7SdJROxuUp9XTF7M7LlUhLAWA26anz2KwC+5O7bzGwGgK1mtqmIfdPd4zQbIcSEoZq93noB9Ba3B8xsD4D28R6YEGJsGdF3djNbDOAWAC8UTfeZ2U4ze9TM4p+KCSHqTtViN7MmAD8B8EV3PwfgIQBLAaxC5cr/9aDfejPrNLNOVqtbCDG+VCV2M2tAReg/cPcnAMDdj7v7VXcfBPBdAGvK+rr7BnfvcPcOVhFFCDG+DCt2qyw/PgJgj7t/Y0h725C7fRxAvFWGEKLuVHOpvQ3AZwDsMrNrqUcPAPi0ma1CxY47AuDzwx2oubkZ69atK4399Kc/Dfu98sorpe2p1hvLXGLWULT1D8ugiraMAuIsOgC49dZbw9i+ffvC2MDAQGk7s7WY1cQ+jbE5jvoxO4llrzU1NYUxVgMwsqJOnz4d9mGPmVloLMaI7E02V9FXYmaHVrMa/xsAZc8q9dSFEBML/YJOiEyQ2IXIBIldiEyQ2IXIBIldiEyo6a9cGhoa0NbWVhpjdlgEK9THstdYvyizDYgtQGbVnDhxIowxC41ZTeyXiNH4mU3GjsfmkWXERbYRmyv2GogsxeH6RY87tdgne32kbNfEjpnyi1M2Pl3ZhcgEiV2ITJDYhcgEiV2ITJDYhcgEiV2ITKip9XblyhX09fWVxvr7+8N+kX2SYrlcG0cEs2Si7LD58+eHfVjs+eefD2OTJ08OY2fPng1j0Zyk2kLjkVmYcrzUftHzmfq42FyxYo8pNuVY99GVXYhMkNiFyASJXYhMkNiFyASJXYhMkNiFyISaWm/uHloDLLsqshlYhg8rvMdg+55F+411dHQkjWP//v1hjNmDzP6JLK9UW4vBnrMoxp4zZnum2GtA2nyw46WOn1mRzC6LiF4DdAwjPosQ4i2JxC5EJkjsQmSCxC5EJkjsQmTCsKvxZtYIYDOAKcX9f+zuXzazGwE8DmAOgK0APuPudAl8YGAAzz77bGmspaUlHmRQtyx1V1hWg47Vfps9u3xX6pMnT4Z9zp8/nzQOVqstpY4bWw1OTShiyTpRUkjqFklvBdiqekqyUYo7MdrV+NcB3O7uK1HZnnmdma0F8FUA33T3PwPQD+DeKo4lhKgTw4rdK1y7PDUU/xzA7QB+XLQ/BuBj4zJCIcSYUO3+7JOKHVz7AGwCcBDAGXe/9jn6GID28RmiEGIsqErs7n7V3VcBWAhgDYA/r/YEZrbezDrNrDP1V21CiNEzotV4dz8D4DkAfwlglpldWylaCKAn6LPB3TvcvYMt6AghxpdhxW5m88xsVnF7KoAPAtiDiuj/prjbPQB+Nl6DFEKMnmoSYdoAPGZmk1B5c9jo7v9lZrsBPG5m/wxgO4BHhjvQwMAAnnvuudJYlGQCxBZVqvXGYIkOkcXG+syaNSuMsU86U6dODWMp1hs7F7PXmD3IbJ6UczELcDySZFL6MAstNVYr621Ysbv7TgC3lLQfQuX7uxDiLYB+QSdEJkjsQmSCxC5EJkjsQmSCxC5EJliKNZF8MrMTAI4Wf84FEKeL1Q6N441oHG/krTaOG9x9XlmgpmJ/w4nNOt09rtSocWgcGseYjkMf44XIBIldiEyop9g31PHcQ9E43ojG8UbeNuOo23d2IURt0cd4ITKhLmI3s3Vm9pKZHTCz++sxhmIcR8xsl5l1mVlnDc/7qJn1mVn3kLYWM9tkZvuL/8urW47/OB40s55iTrrM7MM1GMciM3vOzHab2e/N7O+K9prOCRlHTefEzBrN7EUz21GM45+K9hvN7IVCNz8ys5EViHD3mv4DMAmVslZLAEwGsAPAilqPoxjLEQBz63De9wO4FUD3kLZ/AXB/cft+AF+t0zgeBPD3NZ6PNgC3FrdnANgHYEWt54SMo6ZzAsAANBW3GwC8AGAtgI0APlW0Pwzgb0dy3Hpc2dcAOODuh7xSevpxAHfVYRx1w903Azj9pua7UCncCdSogGcwjprj7r3uvq24PYBKcZR21HhOyDhqilcY8yKv9RB7O4CXh/xdz2KVDuCXZrbVzNbXaQzXaHX33uL2qwBa6ziW+8xsZ/Exf9y/TgzFzBajUj/hBdRxTt40DqDGczIeRV5zX6B7n7vfCuCvAXzBzN5f7wEBlXd2VN6I6sFDAJaiskdAL4Cv1+rEZtYE4CcAvuju54bGajknJeOo+Zz4KIq8RtRD7D0AFg35OyxWOd64e0/xfx+AJ1HfyjvHzawNAIr/++oxCHc/XrzQBgF8FzWaEzNrQEVgP3D3J4rmms9J2TjqNSfFuUdc5DWiHmL/HYBlxcriZACfAvBUrQdhZtPNbMa12wA+BKCb9xpXnkKlcCdQxwKe18RV8HHUYE6sUlDtEQB73P0bQ0I1nZNoHLWek3Er8lqrFcY3rTZ+GJWVzoMA/qFOY1iCihOwA8DvazkOAD9E5ePgZVS+e92Lyp55zwDYD+B/AbTUaRz/DmAXgJ2oiK2tBuN4Hyof0XcC6Cr+fbjWc0LGUdM5AfAXqBRx3YnKG8s/DnnNvgjgAID/BDBlJMfVL+iEyITcF+iEyAaJXYhMkNiFyASJXYhMkNiFyASJXYhMkNiFyASJXYhM+D8aDT/rPkdMxAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MNIST"
      ],
      "metadata": {
        "id": "ArNX2BumLdbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "            datasets.MNIST(root = '/content//MNIST', train=True, download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(28),\n",
        "                               transforms.CenterCrop(28),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize(0.5, 0.5),\n",
        "                           ])),batch_size=9, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "            datasets.MNIST(root = '/content//MNIST', train=False, download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(28),\n",
        "                               transforms.CenterCrop(28),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize(0.5, 0.5),\n",
        "                           ])),batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "1a5jPFuHLckM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MnistCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, kernel_size=3, stride=2)\n",
        "        self.bn = nn.BatchNorm2d(20)\n",
        "        self.conv2 = nn.Conv2d(20, 10, kernel_size=3, stride=3)\n",
        "        self.bn2 = nn.BatchNorm2d(10)\n",
        "        self.fc1 = nn.Linear(10 * 4 * 4, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = x.view(-1, 10 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "model = MnistCNN()"
      ],
      "metadata": {
        "id": "m6yqZQb_MaBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) \n",
        "\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfBEBeY2MgjU",
        "outputId": "eb7fac15-3cd3-4868-dc45-05ebba5f1b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   200] loss: 0.029\n",
            "[1,   400] loss: 0.023\n",
            "[1,   600] loss: 0.022\n",
            "[1,   800] loss: 0.021\n",
            "[1,  1000] loss: 0.021\n",
            "[1,  1200] loss: 0.020\n",
            "[1,  1400] loss: 0.017\n",
            "[1,  1600] loss: 0.017\n",
            "[1,  1800] loss: 0.020\n",
            "[1,  2000] loss: 0.017\n",
            "[1,  2200] loss: 0.019\n",
            "[1,  2400] loss: 0.016\n",
            "[1,  2600] loss: 0.019\n",
            "[1,  2800] loss: 0.016\n",
            "[1,  3000] loss: 0.015\n",
            "[1,  3200] loss: 0.016\n",
            "[1,  3400] loss: 0.014\n",
            "[1,  3600] loss: 0.016\n",
            "[1,  3800] loss: 0.012\n",
            "[1,  4000] loss: 0.013\n",
            "[1,  4200] loss: 0.015\n",
            "[1,  4400] loss: 0.012\n",
            "[1,  4600] loss: 0.012\n",
            "[1,  4800] loss: 0.012\n",
            "[1,  5000] loss: 0.013\n",
            "[1,  5200] loss: 0.014\n",
            "[1,  5400] loss: 0.011\n",
            "[1,  5600] loss: 0.010\n",
            "[1,  5800] loss: 0.015\n",
            "[1,  6000] loss: 0.010\n",
            "[1,  6200] loss: 0.012\n",
            "[1,  6400] loss: 0.009\n",
            "[1,  6600] loss: 0.014\n",
            "[2,   200] loss: 0.011\n",
            "[2,   400] loss: 0.009\n",
            "[2,   600] loss: 0.012\n",
            "[2,   800] loss: 0.009\n",
            "[2,  1000] loss: 0.010\n",
            "[2,  1200] loss: 0.012\n",
            "[2,  1400] loss: 0.010\n",
            "[2,  1600] loss: 0.013\n",
            "[2,  1800] loss: 0.008\n",
            "[2,  2000] loss: 0.010\n",
            "[2,  2200] loss: 0.009\n",
            "[2,  2400] loss: 0.010\n",
            "[2,  2600] loss: 0.009\n",
            "[2,  2800] loss: 0.010\n",
            "[2,  3000] loss: 0.008\n",
            "[2,  3200] loss: 0.009\n",
            "[2,  3400] loss: 0.011\n",
            "[2,  3600] loss: 0.010\n",
            "[2,  3800] loss: 0.010\n",
            "[2,  4000] loss: 0.009\n",
            "[2,  4200] loss: 0.011\n",
            "[2,  4400] loss: 0.009\n",
            "[2,  4600] loss: 0.011\n",
            "[2,  4800] loss: 0.009\n",
            "[2,  5000] loss: 0.008\n",
            "[2,  5200] loss: 0.011\n",
            "[2,  5400] loss: 0.009\n",
            "[2,  5600] loss: 0.008\n",
            "[2,  5800] loss: 0.010\n",
            "[2,  6000] loss: 0.009\n",
            "[2,  6200] loss: 0.007\n",
            "[2,  6400] loss: 0.009\n",
            "[2,  6600] loss: 0.009\n",
            "[3,   200] loss: 0.007\n",
            "[3,   400] loss: 0.010\n",
            "[3,   600] loss: 0.008\n",
            "[3,   800] loss: 0.008\n",
            "[3,  1000] loss: 0.007\n",
            "[3,  1200] loss: 0.007\n",
            "[3,  1400] loss: 0.008\n",
            "[3,  1600] loss: 0.007\n",
            "[3,  1800] loss: 0.008\n",
            "[3,  2000] loss: 0.007\n",
            "[3,  2200] loss: 0.007\n",
            "[3,  2400] loss: 0.006\n",
            "[3,  2600] loss: 0.010\n",
            "[3,  2800] loss: 0.010\n",
            "[3,  3000] loss: 0.008\n",
            "[3,  3200] loss: 0.009\n",
            "[3,  3400] loss: 0.007\n",
            "[3,  3600] loss: 0.008\n",
            "[3,  3800] loss: 0.009\n",
            "[3,  4000] loss: 0.008\n",
            "[3,  4200] loss: 0.009\n",
            "[3,  4400] loss: 0.010\n",
            "[3,  4600] loss: 0.008\n",
            "[3,  4800] loss: 0.007\n",
            "[3,  5000] loss: 0.007\n",
            "[3,  5200] loss: 0.008\n",
            "[3,  5400] loss: 0.008\n",
            "[3,  5600] loss: 0.007\n",
            "[3,  5800] loss: 0.007\n",
            "[3,  6000] loss: 0.009\n",
            "[3,  6200] loss: 0.008\n",
            "[3,  6400] loss: 0.007\n",
            "[3,  6600] loss: 0.007\n",
            "[4,   200] loss: 0.007\n",
            "[4,   400] loss: 0.006\n",
            "[4,   600] loss: 0.007\n",
            "[4,   800] loss: 0.007\n",
            "[4,  1000] loss: 0.009\n",
            "[4,  1200] loss: 0.006\n",
            "[4,  1400] loss: 0.008\n",
            "[4,  1600] loss: 0.009\n",
            "[4,  1800] loss: 0.006\n",
            "[4,  2000] loss: 0.006\n",
            "[4,  2200] loss: 0.006\n",
            "[4,  2400] loss: 0.007\n",
            "[4,  2600] loss: 0.006\n",
            "[4,  2800] loss: 0.007\n",
            "[4,  3000] loss: 0.008\n",
            "[4,  3200] loss: 0.007\n",
            "[4,  3400] loss: 0.006\n",
            "[4,  3600] loss: 0.006\n",
            "[4,  3800] loss: 0.004\n",
            "[4,  4000] loss: 0.006\n",
            "[4,  4200] loss: 0.008\n",
            "[4,  4400] loss: 0.007\n",
            "[4,  4600] loss: 0.005\n",
            "[4,  4800] loss: 0.007\n",
            "[4,  5000] loss: 0.007\n",
            "[4,  5200] loss: 0.006\n",
            "[4,  5400] loss: 0.006\n",
            "[4,  5600] loss: 0.008\n",
            "[4,  5800] loss: 0.008\n",
            "[4,  6000] loss: 0.006\n",
            "[4,  6200] loss: 0.006\n",
            "[4,  6400] loss: 0.006\n",
            "[4,  6600] loss: 0.007\n",
            "[5,   200] loss: 0.006\n",
            "[5,   400] loss: 0.006\n",
            "[5,   600] loss: 0.007\n",
            "[5,   800] loss: 0.006\n",
            "[5,  1000] loss: 0.004\n",
            "[5,  1200] loss: 0.006\n",
            "[5,  1400] loss: 0.006\n",
            "[5,  1600] loss: 0.007\n",
            "[5,  1800] loss: 0.004\n",
            "[5,  2000] loss: 0.007\n",
            "[5,  2200] loss: 0.007\n",
            "[5,  2400] loss: 0.006\n",
            "[5,  2600] loss: 0.007\n",
            "[5,  2800] loss: 0.004\n",
            "[5,  3000] loss: 0.006\n",
            "[5,  3200] loss: 0.006\n",
            "[5,  3400] loss: 0.006\n",
            "[5,  3600] loss: 0.005\n",
            "[5,  3800] loss: 0.008\n",
            "[5,  4000] loss: 0.010\n",
            "[5,  4200] loss: 0.007\n",
            "[5,  4400] loss: 0.005\n",
            "[5,  4600] loss: 0.004\n",
            "[5,  4800] loss: 0.005\n",
            "[5,  5000] loss: 0.006\n",
            "[5,  5200] loss: 0.005\n",
            "[5,  5400] loss: 0.006\n",
            "[5,  5600] loss: 0.007\n",
            "[5,  5800] loss: 0.007\n",
            "[5,  6000] loss: 0.006\n",
            "[5,  6200] loss: 0.006\n",
            "[5,  6400] loss: 0.004\n",
            "[5,  6600] loss: 0.006\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/TFG/MNIST/MNIST_net.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "eeLlij7MQ2_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "print(labels.shape)\n",
        "#net = Net()\n",
        "plt.imshow(images[0].reshape(28,28), cmap=\"gray\")\n",
        "#imshow(images[0])\n",
        "print('GroundTruth: ', ' '.join(f'{labels[j]}' for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "RirI6AjGRNFK",
        "outputId": "28ec4e58-9f8b-4816-ab85-93c43e914db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128])\n",
            "GroundTruth:  9 5 7 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "inputs_box = (min((0 - m) / s for m, s in zip(mean, std)),\n",
        "              max((1 - m) / s for m, s in zip(mean, std)))\n",
        "\n",
        "# a targeted adversary\n",
        "adversary = L2Adversary(targeted=True,\n",
        "                           k=0.0,\n",
        "                           search_steps=10,\n",
        "                           box=inputs_box,\n",
        "                           learning_rate=5e-4)\n",
        "\n",
        "\n",
        "dataiter = iter(train_loader) #inputs images\n",
        "inputs, _ = dataiter.next()\n",
        "inputs.to(device)\n",
        "target_class_idx = 3\n",
        "attack_targets = torch.ones(inputs.size(0)) * target_class_idx #target one-hot encoded\n",
        "\n",
        "\n",
        "adversarial_examples = adversary.attack(model, inputs, attack_targets, NUM_CLASSES)\n",
        "assert isinstance(adversarial_examples, torch.FloatTensor)\n",
        "assert adversarial_examples.size() == inputs.size()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YwDNGhGR56I",
        "outputId": "9dfaa90f-5fbe-43aa-d657-154667103a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "pert_predictions_np: [6 0 1 0 5 5 3 1 3] \n",
            "pert_predictions_np: [3 3 1 0 5 5 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 3 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "batch 460 loss: 87.36589813232422\n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 3 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "batch 470 loss: 87.2808837890625\n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 3 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 5 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 3 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 3 3] \n",
            "batch 480 loss: 87.19924926757812\n",
            "pert_predictions_np: [3 3 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 9 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 3 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [8 3 3 0 5 3 2 3 3] \n",
            "batch 490 loss: 87.11410522460938\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 3 3 3] \n",
            "pert_predictions_np: [6 3 3 0 5 3 3 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "batch 500 loss: 87.01205444335938\n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 3 3 3 5 5 3 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 3 3 3] \n",
            "pert_predictions_np: [8 3 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "batch 510 loss: 86.93089294433594\n",
            "pert_predictions_np: [8 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 3 3 3 5 3 3 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 3 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 3 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "batch 520 loss: 86.85330963134766\n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 3 3 0 5 5 3 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 3 3 3 3] \n",
            "batch 530 loss: 86.76351928710938\n",
            "pert_predictions_np: [6 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 3 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 9 3 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "batch 540 loss: 86.6817626953125\n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 3 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 3] \n",
            "batch 550 loss: 86.61221313476562\n",
            "pert_predictions_np: [5 3 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 3 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 3 3 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 2 3 3] \n",
            "batch 560 loss: 86.52725219726562\n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 1 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 3 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 3 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 3 3] \n",
            "batch 570 loss: 86.45196533203125\n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 3 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 3 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 9 2 3 2] \n",
            "batch 580 loss: 86.37837219238281\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 3 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 3 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [6 3 3 0 5 3 2 3 2] \n",
            "batch 590 loss: 86.30201721191406\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 3 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 3 2] \n",
            "batch 600 loss: 86.2212142944336\n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [5 3 3 0 5 5 3 3 2] \n",
            "pert_predictions_np: [5 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "batch 610 loss: 86.14495849609375\n",
            "pert_predictions_np: [3 3 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 3 3 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 3 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 3 3 0 5 3 3 3 2] \n",
            "batch 620 loss: 86.07920837402344\n",
            "pert_predictions_np: [3 0 3 3 5 3 3 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 3 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "batch 630 loss: 86.00918579101562\n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 9 2 1 3] \n",
            "pert_predictions_np: [5 3 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 3 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "batch 640 loss: 85.93377685546875\n",
            "pert_predictions_np: [8 3 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 3 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "batch 650 loss: 85.85984802246094\n",
            "pert_predictions_np: [6 3 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 3 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 1 3] \n",
            "batch 660 loss: 85.78921508789062\n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 3 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "batch 670 loss: 85.72465515136719\n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 3 3 3] \n",
            "pert_predictions_np: [5 3 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 9 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 3 1 0 5 5 2 1 2] \n",
            "batch 680 loss: 85.65113830566406\n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 3 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 3 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "batch 690 loss: 85.58963012695312\n",
            "pert_predictions_np: [3 0 3 3 5 3 3 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 3 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 3 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 3 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "batch 700 loss: 85.52561950683594\n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 3 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [6 3 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 5 5 2 1 3] \n",
            "batch 710 loss: 85.45439147949219\n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 1 2] \n",
            "pert_predictions_np: [3 3 3 3 5 3 3 1 3] \n",
            "pert_predictions_np: [8 3 1 3 5 5 3 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "batch 720 loss: 85.38578796386719\n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 9 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 3 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 3] \n",
            "batch 730 loss: 85.34074401855469\n",
            "pert_predictions_np: [6 3 1 3 5 5 3 3 2] \n",
            "pert_predictions_np: [3 3 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 3 3 3 5 5 2 3 3] \n",
            "batch 740 loss: 85.26544189453125\n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [8 3 3 0 5 3 3 1 3] \n",
            "pert_predictions_np: [5 3 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "batch 750 loss: 85.2035903930664\n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 9 2 3 3] \n",
            "pert_predictions_np: [8 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 3 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 3 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 3 3] \n",
            "batch 760 loss: 85.14045715332031\n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [8 3 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 3 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 3 1 3] \n",
            "batch 770 loss: 85.06151580810547\n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 3 3 3 5 5 2 3 3] \n",
            "batch 780 loss: 85.00131225585938\n",
            "pert_predictions_np: [3 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [8 3 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 2] \n",
            "batch 790 loss: 84.94180297851562\n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 3 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 3 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 3] \n",
            "batch 800 loss: 84.877197265625\n",
            "pert_predictions_np: [3 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 3 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 3 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 3] \n",
            "batch 810 loss: 84.81294250488281\n",
            "pert_predictions_np: [5 0 3 0 5 9 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [8 3 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 3 1 3] \n",
            "batch 820 loss: 84.75129699707031\n",
            "pert_predictions_np: [8 0 3 3 5 5 3 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 3 3] \n",
            "batch 830 loss: 84.67481231689453\n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 3 3 3] \n",
            "pert_predictions_np: [6 3 1 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 3 3 0 5 5 3 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 3] \n",
            "batch 840 loss: 84.6170425415039\n",
            "pert_predictions_np: [6 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 1 3] \n",
            "pert_predictions_np: [5 3 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 3 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 9 3 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 3 1 3 5 5 2 3 3] \n",
            "batch 850 loss: 84.54466247558594\n",
            "pert_predictions_np: [5 3 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "batch 860 loss: 84.4893798828125\n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [6 3 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 3 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [8 3 3 3 5 5 2 3 3] \n",
            "batch 870 loss: 84.42316436767578\n",
            "pert_predictions_np: [8 3 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 3 3 3] \n",
            "batch 880 loss: 84.36264038085938\n",
            "pert_predictions_np: [6 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 3 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 3] \n",
            "batch 890 loss: 84.27752685546875\n",
            "pert_predictions_np: [8 3 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 3 1 3 5 3 3 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [6 3 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 3 3 3] \n",
            "batch 900 loss: 84.21803283691406\n",
            "pert_predictions_np: [3 3 3 3 5 5 3 3 2] \n",
            "pert_predictions_np: [5 3 3 3 5 9 3 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 3 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 2] \n",
            "batch 910 loss: 84.1468505859375\n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [8 3 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 3 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 3 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 3 1 0 5 5 2 3 2] \n",
            "batch 920 loss: 84.0888900756836\n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [6 3 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 3 3 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 3 3 3 5 5 2 3 3] \n",
            "batch 930 loss: 84.01835632324219\n",
            "pert_predictions_np: [8 3 1 3 5 5 3 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 3 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 3 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 3 3 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 1 3] \n",
            "batch 940 loss: 83.95573425292969\n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 5 9 3 3 2] \n",
            "pert_predictions_np: [6 3 1 3 5 5 3 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 3 3 3] \n",
            "batch 950 loss: 83.89627075195312\n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 5 5 2 1 3] \n",
            "batch 960 loss: 83.82209777832031\n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 3 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 3 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 3 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 2] \n",
            "batch 970 loss: 83.7623519897461\n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 3 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 5 3 3 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 3 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 3 5 3 2 3 3] \n",
            "batch 980 loss: 83.699462890625\n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [5 3 1 3 5 3 3 3 2] \n",
            "pert_predictions_np: [5 3 1 3 5 5 3 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 9 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 3 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "batch 990 loss: 83.64442443847656\n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 3 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 3 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 3 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 3 3 1 3] \n",
            "batch 0 loss: 83.63514709472656\n",
            "pert_predictions_np: [3 3 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "batch 10 loss: 83.559814453125\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "batch 20 loss: 83.49032592773438\n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 2] \n",
            "batch 30 loss: 83.40828704833984\n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 9 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "batch 40 loss: 83.33692932128906\n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "batch 50 loss: 83.25177001953125\n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 9 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 3] \n",
            "batch 60 loss: 83.16270446777344\n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "batch 70 loss: 83.08279418945312\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "batch 80 loss: 83.00318145751953\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 9 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "batch 90 loss: 82.92514038085938\n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "batch 100 loss: 82.85005187988281\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "batch 110 loss: 82.77838897705078\n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 9 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "batch 120 loss: 82.71205139160156\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "batch 130 loss: 82.63776397705078\n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "batch 140 loss: 82.56144714355469\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 9 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "batch 150 loss: 82.49284362792969\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "batch 160 loss: 82.42003631591797\n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 9 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "batch 170 loss: 82.35118103027344\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "batch 180 loss: 82.28105926513672\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "batch 190 loss: 82.21685028076172\n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "batch 200 loss: 82.14937591552734\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 9 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 3] \n",
            "batch 210 loss: 82.08688354492188\n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 2] \n",
            "batch 220 loss: 82.02418518066406\n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 9 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "batch 230 loss: 81.95761108398438\n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "batch 240 loss: 81.89144134521484\n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "batch 250 loss: 81.82363891601562\n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "batch 260 loss: 81.75912475585938\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 9 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "batch 270 loss: 81.69660949707031\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "batch 280 loss: 81.63343048095703\n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "batch 290 loss: 81.56282043457031\n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 9 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "batch 300 loss: 81.50127410888672\n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 3 5 2 1 3] \n",
            "batch 310 loss: 81.43272399902344\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 9 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "batch 320 loss: 81.3701400756836\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 2] \n",
            "batch 330 loss: 81.30799865722656\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 2] \n",
            "batch 340 loss: 81.23902893066406\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "batch 350 loss: 81.17402648925781\n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 9 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "batch 360 loss: 81.10499572753906\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "batch 370 loss: 81.03620910644531\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 9 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "batch 380 loss: 80.96372985839844\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 2] \n",
            "batch 390 loss: 80.89590454101562\n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "batch 400 loss: 80.82711791992188\n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "batch 410 loss: 80.76004791259766\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 9 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 2] \n",
            "batch 420 loss: 80.68740844726562\n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "batch 430 loss: 80.61752319335938\n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 9 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 3 2] \n",
            "batch 440 loss: 80.54756164550781\n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 3] \n",
            "batch 450 loss: 80.47826385498047\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "batch 460 loss: 80.40275573730469\n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 9 2 3 3] \n",
            "batch 470 loss: 80.32960510253906\n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "batch 480 loss: 80.26068115234375\n",
            "pert_predictions_np: [8 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 2] \n",
            "batch 490 loss: 80.1862564086914\n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "batch 500 loss: 80.11189270019531\n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 9 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 3] \n",
            "batch 510 loss: 80.0345687866211\n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "batch 520 loss: 79.95884704589844\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 9 2 1 3] \n",
            "batch 530 loss: 79.8831558227539\n",
            "pert_predictions_np: [6 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "batch 540 loss: 79.80570220947266\n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "batch 550 loss: 79.72969055175781\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "batch 560 loss: 79.65664672851562\n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 9 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "batch 570 loss: 79.57902526855469\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "batch 580 loss: 79.50281524658203\n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "batch 590 loss: 79.41949462890625\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 9 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 3] \n",
            "batch 600 loss: 79.34078979492188\n",
            "pert_predictions_np: [8 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "batch 610 loss: 79.26329040527344\n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "batch 620 loss: 79.1849365234375\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "batch 630 loss: 79.10433959960938\n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 9 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "batch 640 loss: 79.0181884765625\n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "batch 650 loss: 78.93681335449219\n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "batch 660 loss: 78.85272979736328\n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "batch 670 loss: 78.76757049560547\n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 9 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "batch 680 loss: 78.68580627441406\n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "batch 690 loss: 78.59600830078125\n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 3] \n",
            "batch 700 loss: 78.5143051147461\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "batch 710 loss: 78.42328643798828\n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "batch 720 loss: 78.33451080322266\n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 9 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 3 3 2 1 2] \n",
            "batch 730 loss: 78.24429321289062\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 2] \n",
            "batch 740 loss: 78.15673828125\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "batch 750 loss: 78.06575775146484\n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "batch 760 loss: 77.97577667236328\n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "batch 770 loss: 77.88247680664062\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 9 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "batch 780 loss: 77.79349517822266\n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "batch 790 loss: 77.69818115234375\n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 3] \n",
            "batch 800 loss: 77.6085205078125\n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 2] \n",
            "batch 810 loss: 77.50982666015625\n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "batch 820 loss: 77.41658020019531\n",
            "pert_predictions_np: [3 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 9 2 3 2] \n",
            "batch 830 loss: 77.32193756103516\n",
            "pert_predictions_np: [5 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [8 3 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "batch 840 loss: 77.22747802734375\n",
            "pert_predictions_np: [5 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "batch 850 loss: 77.13809204101562\n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 3 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 3 2 1 3] \n",
            "batch 860 loss: 77.04290008544922\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 3 3] \n",
            "batch 870 loss: 76.944091796875\n",
            "pert_predictions_np: [8 3 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 3 3 0 5 3 2 1 3] \n",
            "batch 880 loss: 76.84912109375\n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "batch 890 loss: 76.75118255615234\n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 1 3] \n",
            "batch 900 loss: 76.64576721191406\n",
            "pert_predictions_np: [5 0 3 3 5 9 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 2] \n",
            "batch 910 loss: 76.54795837402344\n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [8 3 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 5 5 2 3 3] \n",
            "batch 920 loss: 76.44483184814453\n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "batch 930 loss: 76.34413146972656\n",
            "pert_predictions_np: [8 3 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "batch 940 loss: 76.24394226074219\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 3 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "batch 950 loss: 76.13846588134766\n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "batch 960 loss: 76.03123474121094\n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 3 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 3 5 5 2 3 2] \n",
            "batch 970 loss: 75.93360900878906\n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "batch 980 loss: 75.83411407470703\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 3 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 3 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 1 3] \n",
            "batch 990 loss: 75.72555541992188\n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 3 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 5 5 2 1 3] \n",
            "batch 0 loss: 75.60490417480469\n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "batch 10 loss: 75.48932647705078\n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "batch 20 loss: 75.36781311035156\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "batch 30 loss: 75.24832153320312\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "batch 40 loss: 75.12574005126953\n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "batch 50 loss: 75.00465393066406\n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "batch 60 loss: 74.88504791259766\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "batch 70 loss: 74.76863098144531\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "batch 80 loss: 74.64810180664062\n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "batch 90 loss: 74.530029296875\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "batch 100 loss: 74.41358947753906\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "batch 110 loss: 74.2962875366211\n",
            "pert_predictions_np: [5 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "batch 120 loss: 74.17967987060547\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "batch 130 loss: 74.06472778320312\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "batch 140 loss: 73.94644165039062\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "batch 150 loss: 73.8307113647461\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "batch 160 loss: 73.71363830566406\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "batch 170 loss: 73.5950698852539\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "batch 180 loss: 73.47674560546875\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "batch 190 loss: 73.35774230957031\n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 1 2] \n",
            "batch 200 loss: 73.23880767822266\n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "batch 210 loss: 73.12084197998047\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "batch 220 loss: 73.00102233886719\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "batch 230 loss: 72.8829345703125\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "batch 240 loss: 72.7633056640625\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "batch 250 loss: 72.64424133300781\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "batch 260 loss: 72.52496337890625\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "batch 270 loss: 72.40290832519531\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "batch 280 loss: 72.28193664550781\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "batch 290 loss: 72.16360473632812\n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "batch 300 loss: 72.03813171386719\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "batch 310 loss: 71.9141616821289\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "batch 320 loss: 71.79196166992188\n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "batch 330 loss: 71.66803741455078\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "batch 340 loss: 71.54473876953125\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "batch 350 loss: 71.41661071777344\n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "batch 360 loss: 71.29046630859375\n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "batch 370 loss: 71.16043090820312\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "batch 380 loss: 71.03271484375\n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "batch 390 loss: 70.90145874023438\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "batch 400 loss: 70.76683044433594\n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 2] \n",
            "batch 410 loss: 70.63328552246094\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "batch 420 loss: 70.50187683105469\n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "batch 430 loss: 70.3658447265625\n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 2] \n",
            "batch 440 loss: 70.23035430908203\n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "batch 450 loss: 70.09333801269531\n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "batch 460 loss: 69.95841979980469\n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "batch 470 loss: 69.81847381591797\n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 3] \n",
            "batch 480 loss: 69.68106842041016\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "batch 490 loss: 69.54383850097656\n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "batch 500 loss: 69.40176391601562\n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "batch 510 loss: 69.25785827636719\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "batch 520 loss: 69.11468505859375\n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 3] \n",
            "batch 530 loss: 68.97047424316406\n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "batch 540 loss: 68.82408142089844\n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 1 3] \n",
            "batch 550 loss: 68.67523193359375\n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "batch 560 loss: 68.526611328125\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "batch 570 loss: 68.3785400390625\n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "batch 580 loss: 68.2287826538086\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "batch 590 loss: 68.0800552368164\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 2] \n",
            "batch 600 loss: 67.92877960205078\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "batch 610 loss: 67.77513122558594\n",
            "pert_predictions_np: [5 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "batch 620 loss: 67.6221923828125\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 3 3 2 3 3] \n",
            "batch 630 loss: 67.46865844726562\n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 3 3 5 2 3 3] \n",
            "batch 640 loss: 67.31549072265625\n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "batch 650 loss: 67.16194152832031\n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 1 3] \n",
            "batch 660 loss: 67.00676727294922\n",
            "pert_predictions_np: [5 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "batch 670 loss: 66.8603286743164\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "batch 680 loss: 66.70758056640625\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "batch 690 loss: 66.55891418457031\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "batch 700 loss: 66.40519714355469\n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "batch 710 loss: 66.25830078125\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "batch 720 loss: 66.10714721679688\n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "batch 730 loss: 65.96134948730469\n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 3 3 5 2 3 2] \n",
            "batch 740 loss: 65.81204223632812\n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "batch 750 loss: 65.66105651855469\n",
            "pert_predictions_np: [8 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "batch 760 loss: 65.51072692871094\n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "batch 770 loss: 65.36339569091797\n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "batch 780 loss: 65.21148681640625\n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "batch 790 loss: 65.0631103515625\n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 2] \n",
            "batch 800 loss: 64.91497039794922\n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "batch 810 loss: 64.76177978515625\n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "batch 820 loss: 64.61966705322266\n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [6 3 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 3 3] \n",
            "batch 830 loss: 64.47227478027344\n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "batch 840 loss: 64.32303619384766\n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 3 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "batch 850 loss: 64.17647552490234\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "batch 860 loss: 64.02565002441406\n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 3 1 3 5 5 2 1 2] \n",
            "batch 870 loss: 63.87607192993164\n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 3 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 3] \n",
            "batch 880 loss: 63.72871398925781\n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "batch 890 loss: 63.579925537109375\n",
            "pert_predictions_np: [5 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 1 2] \n",
            "batch 900 loss: 63.43251419067383\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 3 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "batch 910 loss: 63.2877197265625\n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 3 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "batch 920 loss: 63.13915252685547\n",
            "pert_predictions_np: [6 3 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "batch 930 loss: 62.99327087402344\n",
            "pert_predictions_np: [5 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 3 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 3 3 0 3 5 2 1 2] \n",
            "batch 940 loss: 62.84562683105469\n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [3 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 3 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "batch 950 loss: 62.700950622558594\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "batch 960 loss: 62.55079650878906\n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 3 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [8 3 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "batch 970 loss: 62.407249450683594\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 3 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 3 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "batch 980 loss: 62.26291275024414\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 3 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 3 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "batch 990 loss: 62.116973876953125\n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 3 1 3 5 3 2 1 2] \n",
            "batch 0 loss: 61.9719123840332\n",
            "pert_predictions_np: [5 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "batch 10 loss: 61.81544876098633\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "batch 20 loss: 61.65925598144531\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "batch 30 loss: 61.502864837646484\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "batch 40 loss: 61.34650421142578\n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "batch 50 loss: 61.19055938720703\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "batch 60 loss: 61.03253173828125\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "batch 70 loss: 60.875370025634766\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "batch 80 loss: 60.718807220458984\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "batch 90 loss: 60.56269073486328\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "batch 100 loss: 60.40693664550781\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "batch 110 loss: 60.25056076049805\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "batch 120 loss: 60.0941047668457\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "batch 130 loss: 59.93703079223633\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "batch 140 loss: 59.78212356567383\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "batch 150 loss: 59.62589645385742\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "batch 160 loss: 59.470211029052734\n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "batch 170 loss: 59.315608978271484\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "batch 180 loss: 59.158653259277344\n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "batch 190 loss: 59.00409698486328\n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "batch 200 loss: 58.84742736816406\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "batch 210 loss: 58.692848205566406\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "batch 220 loss: 58.540130615234375\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "batch 230 loss: 58.38677215576172\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "batch 240 loss: 58.23468017578125\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "batch 250 loss: 58.080474853515625\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "batch 260 loss: 57.91856384277344\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "batch 270 loss: 57.73807144165039\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 3] \n",
            "batch 280 loss: 57.55537414550781\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 3] \n",
            "batch 290 loss: 57.370262145996094\n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "batch 300 loss: 57.19078063964844\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 2] \n",
            "batch 310 loss: 57.01482009887695\n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 3 1 3 3 5 2 1 2] \n",
            "batch 320 loss: 56.84202575683594\n",
            "pert_predictions_np: [5 3 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 2] \n",
            "batch 330 loss: 56.66727066040039\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 3 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "batch 340 loss: 56.49604034423828\n",
            "pert_predictions_np: [5 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 3] \n",
            "batch 350 loss: 56.320770263671875\n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 3 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 3 3] \n",
            "batch 360 loss: 56.14890670776367\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 3 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "batch 370 loss: 55.97845458984375\n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 3 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 3] \n",
            "batch 380 loss: 55.8085823059082\n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 3 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 3] \n",
            "batch 390 loss: 55.63836669921875\n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 3 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "batch 400 loss: 55.473594665527344\n",
            "pert_predictions_np: [8 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "batch 410 loss: 55.307899475097656\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 3 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "batch 420 loss: 55.14635467529297\n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 3 5 2 3 3] \n",
            "batch 430 loss: 54.9844970703125\n",
            "pert_predictions_np: [3 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "batch 440 loss: 54.825016021728516\n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 3 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "batch 450 loss: 54.6688232421875\n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 3 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "batch 460 loss: 54.51221466064453\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 3 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 3] \n",
            "batch 470 loss: 54.35909652709961\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 3 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "batch 480 loss: 54.204551696777344\n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "batch 490 loss: 54.05536651611328\n",
            "pert_predictions_np: [5 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "batch 500 loss: 53.90441131591797\n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "batch 510 loss: 53.75611877441406\n",
            "pert_predictions_np: [8 3 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "batch 520 loss: 53.60757827758789\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 3 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "batch 530 loss: 53.45933532714844\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 2] \n",
            "batch 540 loss: 53.31317901611328\n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [5 3 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "batch 550 loss: 53.17098617553711\n",
            "pert_predictions_np: [5 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "batch 560 loss: 53.02667236328125\n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 2] \n",
            "batch 570 loss: 52.88164138793945\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [8 3 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "batch 580 loss: 52.74041748046875\n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 3 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "batch 590 loss: 52.59723663330078\n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 3 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "batch 600 loss: 52.45750427246094\n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 3 3 3 5 5 2 1 2] \n",
            "batch 610 loss: 52.31578063964844\n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 3 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "batch 620 loss: 52.176666259765625\n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 3 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "batch 630 loss: 52.03839874267578\n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 3 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "batch 640 loss: 51.898887634277344\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 3 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "batch 650 loss: 51.760955810546875\n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 3 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "batch 660 loss: 51.62533950805664\n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 3 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 3 3 3 2 3 2] \n",
            "batch 670 loss: 51.48793029785156\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "batch 680 loss: 51.34872817993164\n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 3 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "batch 690 loss: 51.206809997558594\n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 3 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [8 3 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 3] \n",
            "batch 700 loss: 51.06399154663086\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 3 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 3 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "batch 710 loss: 50.91956329345703\n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 3 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 3 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "batch 720 loss: 50.77754592895508\n",
            "pert_predictions_np: [6 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 3 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "batch 730 loss: 50.63196563720703\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "batch 740 loss: 50.49148178100586\n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 3 3 2] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 3 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 3 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "batch 750 loss: 50.347633361816406\n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 3] \n",
            "batch 760 loss: 50.20397186279297\n",
            "pert_predictions_np: [6 3 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "batch 770 loss: 50.065006256103516\n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "batch 780 loss: 49.92387008666992\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 3 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 3 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "batch 790 loss: 49.79095458984375\n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [8 3 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "batch 800 loss: 49.65235900878906\n",
            "pert_predictions_np: [6 0 1 0 5 3 3 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [5 3 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "batch 810 loss: 49.517364501953125\n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 3 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 3 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "batch 820 loss: 49.384666442871094\n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [5 3 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "batch 830 loss: 49.25086212158203\n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 3 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "batch 840 loss: 49.12001419067383\n",
            "pert_predictions_np: [5 0 1 3 5 3 3 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [8 3 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 3 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 3] \n",
            "batch 850 loss: 48.98686218261719\n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [8 3 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "batch 860 loss: 48.85839080810547\n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 3 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 3] \n",
            "batch 870 loss: 48.735130310058594\n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [5 3 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 3 3 3] \n",
            "batch 880 loss: 48.60316467285156\n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 3 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "batch 890 loss: 48.472877502441406\n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "batch 900 loss: 48.34721374511719\n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 1 2] \n",
            "batch 910 loss: 48.218929290771484\n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 3 1 2] \n",
            "pert_predictions_np: [3 3 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 3 3 3 3 5 2 1 2] \n",
            "batch 920 loss: 48.098167419433594\n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "batch 930 loss: 47.98113250732422\n",
            "pert_predictions_np: [6 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 3 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 2] \n",
            "batch 940 loss: 47.857704162597656\n",
            "pert_predictions_np: [6 3 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 3 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 3 1 3] \n",
            "batch 950 loss: 47.738285064697266\n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 3 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 1 3] \n",
            "batch 960 loss: 47.62158966064453\n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 3] \n",
            "batch 970 loss: 47.50111389160156\n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 3 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 2] \n",
            "batch 980 loss: 47.37841033935547\n",
            "pert_predictions_np: [8 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 3 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 3 1 0 3 5 3 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 2] \n",
            "batch 990 loss: 47.25883865356445\n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 3 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "batch 0 loss: 47.138145446777344\n",
            "pert_predictions_np: [6 3 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "batch 10 loss: 47.01564025878906\n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 3 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 3 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "batch 20 loss: 46.89542770385742\n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 3 1 2] \n",
            "batch 30 loss: 46.78179931640625\n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "batch 40 loss: 46.66978073120117\n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 3 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "batch 50 loss: 46.55110168457031\n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 3 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 3 3 3 5 3 2 3 2] \n",
            "batch 60 loss: 46.44013595581055\n",
            "pert_predictions_np: [8 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 3 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "batch 70 loss: 46.32680892944336\n",
            "pert_predictions_np: [5 3 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "batch 80 loss: 46.21473693847656\n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 3 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "batch 90 loss: 46.106239318847656\n",
            "pert_predictions_np: [3 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 3] \n",
            "batch 100 loss: 45.99433135986328\n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "batch 110 loss: 45.885398864746094\n",
            "pert_predictions_np: [5 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 3 3 0 3 3 3 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 3 3 3 5 5 2 3 2] \n",
            "batch 120 loss: 45.776798248291016\n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 3 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "batch 130 loss: 45.671424865722656\n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 3 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 3 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 3] \n",
            "batch 140 loss: 45.565643310546875\n",
            "pert_predictions_np: [5 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "batch 150 loss: 45.46331024169922\n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 3 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 3 3 1 2] \n",
            "pert_predictions_np: [6 3 3 3 5 3 2 1 3] \n",
            "batch 160 loss: 45.35936737060547\n",
            "pert_predictions_np: [6 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 3] \n",
            "batch 170 loss: 45.25707244873047\n",
            "pert_predictions_np: [3 3 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 3 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 3] \n",
            "batch 180 loss: 45.15216827392578\n",
            "pert_predictions_np: [3 3 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 3 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "batch 190 loss: 45.047977447509766\n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 3 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 3] \n",
            "batch 200 loss: 44.947967529296875\n",
            "pert_predictions_np: [8 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 3 3 0 3 3 3 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [5 3 1 0 5 3 2 1 2] \n",
            "batch 210 loss: 44.84636688232422\n",
            "pert_predictions_np: [6 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 3 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "batch 220 loss: 44.749961853027344\n",
            "pert_predictions_np: [3 3 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 3 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "batch 230 loss: 44.64503479003906\n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 3] \n",
            "batch 240 loss: 44.54853057861328\n",
            "pert_predictions_np: [8 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 3 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "batch 250 loss: 44.45196533203125\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 3 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 3 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 3 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 3] \n",
            "batch 260 loss: 44.35020065307617\n",
            "pert_predictions_np: [3 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 3 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [8 3 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "batch 270 loss: 44.24943923950195\n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 3 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 2] \n",
            "batch 280 loss: 44.14519500732422\n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 3 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 3 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 3 1 0 3 3 2 1 3] \n",
            "batch 290 loss: 44.04536437988281\n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "batch 300 loss: 43.940303802490234\n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 3 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 3] \n",
            "batch 310 loss: 43.83944320678711\n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 3 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 3 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "batch 320 loss: 43.74280548095703\n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 3 2] \n",
            "batch 330 loss: 43.647708892822266\n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 3 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 3 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [8 3 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "batch 340 loss: 43.54096221923828\n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 3 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "batch 350 loss: 43.44453430175781\n",
            "pert_predictions_np: [6 3 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "batch 360 loss: 43.34541320800781\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 3 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "batch 370 loss: 43.24565124511719\n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 3 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "batch 380 loss: 43.149662017822266\n",
            "pert_predictions_np: [8 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 3 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [8 3 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 2] \n",
            "batch 390 loss: 43.053001403808594\n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 3 5 2 3 3] \n",
            "batch 400 loss: 42.954681396484375\n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 3 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "batch 410 loss: 42.858848571777344\n",
            "pert_predictions_np: [3 3 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [5 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 3 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "batch 420 loss: 42.76898193359375\n",
            "pert_predictions_np: [8 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 3 3] \n",
            "batch 430 loss: 42.67597961425781\n",
            "pert_predictions_np: [6 3 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 3 3 3 3 3 2 1 3] \n",
            "batch 440 loss: 42.582149505615234\n",
            "pert_predictions_np: [3 3 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 3 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "batch 450 loss: 42.48857116699219\n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 3 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "batch 460 loss: 42.39946746826172\n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "batch 470 loss: 42.31090545654297\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 3 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "batch 480 loss: 42.22051239013672\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 3 3 0 3 3 2 3 3] \n",
            "batch 490 loss: 42.128746032714844\n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 3 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 2] \n",
            "batch 500 loss: 42.044857025146484\n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 3 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 3 1 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n",
            "batch 510 loss: 41.96282958984375\n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "batch 520 loss: 41.87257385253906\n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 3 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 3 1 3 3 3 2 3 3] \n",
            "batch 530 loss: 41.787132263183594\n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 3 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "batch 540 loss: 41.71170425415039\n",
            "pert_predictions_np: [8 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 3 1 3 3 3 2 1 3] \n",
            "batch 550 loss: 41.62544250488281\n",
            "pert_predictions_np: [3 3 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 3] \n",
            "batch 560 loss: 41.54079818725586\n",
            "pert_predictions_np: [6 3 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 3 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 3 3] \n",
            "batch 570 loss: 41.45671081542969\n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 3 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 3 3] \n",
            "batch 580 loss: 41.37645721435547\n",
            "pert_predictions_np: [8 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 3 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 3] \n",
            "batch 590 loss: 41.300636291503906\n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "batch 600 loss: 41.220489501953125\n",
            "pert_predictions_np: [3 3 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 3 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "batch 610 loss: 41.140235900878906\n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 3 3 0 3 3 2 1 3] \n",
            "batch 620 loss: 41.063026428222656\n",
            "pert_predictions_np: [3 0 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 2] \n",
            "batch 630 loss: 40.983070373535156\n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 3 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 3 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "batch 640 loss: 40.90531921386719\n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 3 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 7 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "batch 650 loss: 40.82837677001953\n",
            "pert_predictions_np: [5 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 3 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 3 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "batch 660 loss: 40.75086975097656\n",
            "pert_predictions_np: [6 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 3 3 0 3 5 2 7 2] \n",
            "pert_predictions_np: [5 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 1 3] \n",
            "batch 670 loss: 40.67279052734375\n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 3 3 3 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 3] \n",
            "batch 680 loss: 40.5963020324707\n",
            "pert_predictions_np: [6 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 7 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "batch 690 loss: 40.523101806640625\n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 3 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 3 1 0 5 3 2 3 3] \n",
            "batch 700 loss: 40.449501037597656\n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 7 2] \n",
            "batch 710 loss: 40.37017059326172\n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 3 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [3 3 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [5 3 3 0 3 3 2 1 3] \n",
            "batch 720 loss: 40.30073165893555\n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 7 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 3 3] \n",
            "batch 730 loss: 40.223899841308594\n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 3] \n",
            "batch 740 loss: 40.15315246582031\n",
            "pert_predictions_np: [5 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 3 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [8 3 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 2] \n",
            "batch 750 loss: 40.081634521484375\n",
            "pert_predictions_np: [6 0 3 0 5 3 2 7 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 3 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 2] \n",
            "batch 760 loss: 40.01190948486328\n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [5 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 3 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 3] \n",
            "batch 770 loss: 39.940799713134766\n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 7 2] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 7 2] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 3 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 1 2] \n",
            "batch 780 loss: 39.86759948730469\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 2] \n",
            "batch 790 loss: 39.794795989990234\n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 3 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 2] \n",
            "batch 800 loss: 39.72673416137695\n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 3 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 7 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "batch 810 loss: 39.65595245361328\n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 3 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 5 5 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [8 3 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "batch 820 loss: 39.58576202392578\n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 7 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 0 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [5 3 3 0 3 3 2 1 2] \n",
            "batch 830 loss: 39.519126892089844\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 3 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 5 3 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 3] \n",
            "batch 840 loss: 39.45561218261719\n",
            "pert_predictions_np: [3 3 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 7 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 3 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 3 3] \n",
            "batch 850 loss: 39.389686584472656\n",
            "pert_predictions_np: [8 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 3 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 3 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 7 3] \n",
            "batch 860 loss: 39.32554626464844\n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [8 3 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 3 1 3 5 3 2 1 2] \n",
            "batch 870 loss: 39.258094787597656\n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 1 0 3 5 2 7 2] \n",
            "pert_predictions_np: [6 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 3 1 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 3 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 3 3] \n",
            "batch 880 loss: 39.189456939697266\n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 2] \n",
            "pert_predictions_np: [8 3 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 1 3] \n",
            "batch 890 loss: 39.123985290527344\n",
            "pert_predictions_np: [6 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 5 2 7 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [5 3 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 3 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "batch 900 loss: 39.0666389465332\n",
            "pert_predictions_np: [6 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 0 3 5 2 1 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [3 3 1 3 5 5 2 1 2] \n",
            "pert_predictions_np: [3 0 1 3 3 5 2 7 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "batch 910 loss: 39.007171630859375\n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 1 3] \n",
            "pert_predictions_np: [8 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [6 3 3 0 3 5 2 1 3] \n",
            "pert_predictions_np: [6 3 3 0 5 5 2 1 2] \n",
            "batch 920 loss: 38.93901062011719\n",
            "pert_predictions_np: [5 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 3 5 5 2 7 2] \n",
            "pert_predictions_np: [6 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n",
            "batch 930 loss: 38.877742767333984\n",
            "pert_predictions_np: [6 3 3 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 3 3 0 5 5 2 1 3] \n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 7 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 3] \n",
            "batch 940 loss: 38.81390380859375\n",
            "pert_predictions_np: [6 0 3 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 3 1 3 5 3 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 2] \n",
            "pert_predictions_np: [3 3 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [8 0 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [8 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 5 5 2 3 2] \n",
            "batch 950 loss: 38.75041198730469\n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 3 3 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 5 5 2 3 2] \n",
            "pert_predictions_np: [6 3 3 0 5 5 2 7 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 1 3] \n",
            "batch 960 loss: 38.69082260131836\n",
            "pert_predictions_np: [3 0 1 3 3 5 2 3 2] \n",
            "pert_predictions_np: [8 0 1 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 1 2] \n",
            "pert_predictions_np: [6 3 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 5 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 1 2] \n",
            "pert_predictions_np: [6 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [6 3 1 3 3 3 2 1 3] \n",
            "batch 970 loss: 38.62916564941406\n",
            "pert_predictions_np: [3 0 3 3 3 3 2 3 2] \n",
            "pert_predictions_np: [5 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [6 3 1 0 5 3 2 7 3] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 7 2] \n",
            "pert_predictions_np: [3 0 1 3 5 3 2 1 2] \n",
            "pert_predictions_np: [8 0 3 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 0 3 5 2 3 3] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 3 2] \n",
            "batch 980 loss: 38.56721496582031\n",
            "pert_predictions_np: [6 3 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 3 3] \n",
            "pert_predictions_np: [3 0 1 3 3 3 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 5 3 2 1 3] \n",
            "pert_predictions_np: [6 0 3 0 5 3 2 1 2] \n",
            "pert_predictions_np: [6 0 1 0 5 3 2 3 2] \n",
            "pert_predictions_np: [3 0 3 0 3 3 2 3 3] \n",
            "pert_predictions_np: [3 3 1 3 3 5 2 3 3] \n",
            "pert_predictions_np: [6 3 3 3 3 5 2 1 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 1 2] \n",
            "batch 990 loss: 38.510093688964844\n",
            "pert_predictions_np: [8 0 3 0 3 3 2 3 2] \n",
            "pert_predictions_np: [6 0 1 0 3 3 2 3 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 1 3] \n",
            "pert_predictions_np: [8 0 3 3 5 3 2 3 3] \n",
            "pert_predictions_np: [6 0 3 3 5 3 2 1 3] \n",
            "pert_predictions_np: [3 0 1 0 5 5 2 3 3] \n",
            "pert_predictions_np: [3 0 3 0 3 5 2 3 2] \n",
            "pert_predictions_np: [6 0 3 0 3 5 2 1 2] \n",
            "pert_predictions_np: [5 0 1 3 3 3 2 1 2] \n",
            "pert_predictions_np: [3 0 1 0 3 3 2 3 2] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision as TV\n",
        "inv_normalize = transforms.Normalize(\n",
        "        mean=mean,\n",
        "        std=std\n",
        "      )\n",
        "\n",
        "plt.imshow(inputs[0].reshape(28,28), cmap=\"gray\")\n",
        "plt.imshow(adversarial_examples[0].reshape(28,28), cmap=\"gray\")  \n",
        "for i in range(0,adversarial_examples.size()[0]):\n",
        "  #print(inputs[i].size())\n",
        "  plt.imshow(inputs[i].reshape(28,28), cmap=\"gray\")\n",
        "  inv =inputs[i] / 2 + 0.5\n",
        "  TV.utils.save_image(inputs[i].reshape(28,28), \"/content/drive/MyDrive/TFG/CW/logs/%d_original.png\" %(i),)\n",
        " \n",
        "  inv =adversarial_examples[i] / 2 + 0.5\n",
        "  TV.utils.save_image(adversarial_examples[i].reshape(28,28), \"/content/drive/MyDrive/TFG/CW/logs/%d_adversarial.png\" %(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "rcrHB4kdST2O",
        "outputId": "e59a36be-1c48-41c6-c864-349d117ed16e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}